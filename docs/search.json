[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 210: Regression Analysis",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester. Note that this schedule will be updated as the semester progresses, with all changes documented here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek\nDate\nTopic\nPrepare\nSlides\nAE\nLab\nHW\nExam\nProject\n\n\n\n\n1\nWed, Jan 5\nLab 0 - Meet + greet\n\nüñ•Ô∏è\n\nüíª\n\n\n\n\n\n\nThu, Jan 6\nWelcome to STA 210!\nüìñ\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n2\nMon, Jan 10\nLab 1 - Meet the toolkit\n\nüñ•Ô∏è\n\nüíª\n\n\n\n\n\n\nTue, Jan 11\nSimple linear regression (SLR)\nüìñ\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nThu, Jan 13\nSLR: Model fitting in R with tidymodels\n\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\nFri, Jan 14\nReleased: HW 5\n\n\n\n\n‚úçÔ∏è\n\n\n\n\n\n\nDue: Lab 1\n\n\n\nüíª üóùÔ∏è\n\n\n\n\n\n3\nMon, Jan 17\nMartin Luther King, Jr.¬†Day\n\n\n\n\n\n\n\n\n\n\nTue, Jan 18\nSLR: Prediction + model evaluation\nüìñ\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\nThu, Jan 20\nSLR: Simulation-based inference\n\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nFri, Jan 21\nReleased: HW 1\n\n\n\n\n‚úçÔ∏è\n\n\n\n\n4\nMon, Jan 24\nLab 2 - College scorecard\n\nüñ•Ô∏è\n\nüíª\n\n\n\n\n\n\nTue, Jan 25\nSLR: Mathematical models for inference\nüìñ\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nThu, Jan 27\nSLR: Model diagnostics\n\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\nFri, Jan 28\nDue: HW 1 + Lab 2\n\n\n\nüíª üóùÔ∏è\n‚úçÔ∏è üóùÔ∏è\n\n\n\n\n5\nMon, Jan 31\nLab 3 - Coffee ratings\n\nüñ•Ô∏è\n\nüíª\n\n\n\n\n\n\nTue, Feb 1\nMultiple linear regression (MLR)\nüìñ\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nThu, Feb 3\nExam 1 review\n\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\nFri, Feb 4\nReleased: Exam 1\n\n\n\n\n\n‚úÖ\n\n\n\n\n\nDue: Lab 3\n\n\n\nüíª üóùÔ∏è\n\n\n\n\n\n6\nMon, Feb 7\nNo lab: Work on Exam 1\n\n\n\n\n\n\n\n\n\n\n\nDue: Exam 1\n\n\n\n\n\n‚úÖ\n\n\n\n\nTue, Feb 8\nMLR: Types of predictors\nüìñ\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nThu, Feb 10\nMLR: Model comparison\n\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nFri, Feb 11\nReleased: HW 2\n\n\n\n\n‚úçÔ∏è\n\n\n\n\n7\nMon, Feb 14\nLab: Project topic ideas\n\n\n\n\n\n\nüìÇ\n\n\n\nTue, Feb 15\nMLR: Feature engineering\nüìñ\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\nThu, Feb 17\nMLR: Feature engineering\n\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nFri, Feb 18\nDue: HW 2 + Project topic ideas\n\n\n\n\n‚úçÔ∏è üóùÔ∏è\n\nüìÇ\n\n\n8\nMon, Feb 21\nLab 4: The Office\n\n\n\nüíª\n\n\n\n\n\n\nTue, Feb 22\nMLR: Cross validation\nüìñ\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\nThu, Feb 24\nExam 2 review\n\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\nFri, Feb 25\nReleased: Exam 2\n\n\n\n\n\n‚úÖ\n\n\n\n\n\nDue: Lab 4\n\n\n\nüíª üóùÔ∏è\n\n\n\n\n\n9\nMon, Feb 28\nNo lab: Work on Exam 2\n\n\n\n\n\n\n\n\n\n\n\nDue: Exam 2\n\n\n\n\n\n‚úÖ\n\n\n\n\nTue, Mar 1\nMLR: Inference\nüìñ\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\nThu, Mar 3\nMLR: Inference conditions + multicollinearity\n\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nMon, Mar 7\nSpring break\n\n\n\n\n\n\n\n\n\n\nTue, Mar 8\nSpring break\n\n\n\n\n\n\n\n\n\n\nThu, Mar 10\nSpring break\n\n\n\n\n\n\n\n\n\n10\nMon, Mar 14\nLab: Work on project proposals\n\n\n\n\n\n\nüìÇ\n\n\n\nTue, Mar 15\nLogistic regression (LR)\nüìñ\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\nThu, Mar 17\nProbabilities, odds, and odds ratios\n\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nFri, Mar 18\nDue: Project proposals\n\n\n\n\n\n\nüìÇ\n\n\n\n\nReleased: HW 3\n\n\n\n\n‚úçÔ∏è\n\n\n\n\n11\nMon, Mar 21\nLab 5: General Social Survey\n\n\n\nüíª\n\n\n\n\n\n\nTue, Mar 22\nLR: Prediction / classification\nüìñ\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nThu, Mar 24\nLR: Model comparison\n\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\nFri, Mar 25\nDue: HW 3 + Lab 5\n\n\n\nüíª üóùÔ∏è\n‚úçÔ∏è üóùÔ∏è\n\n\n\n\n12\nMon, Mar 28\nLab: Work on project drafts\n\n\n\n\n\n\nüìÇ\n\n\n\nTue, Mar 29\nLR: Inference + conditions\nüìñ\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nThu, Mar 31\nMultinomial Logistic Regression (MultiLR)\n\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nFri, Apr 1\nReleased: HW 4\n\n\n\n\n‚úçÔ∏è\n\n\n\n\n13\nMon, Apr 4\nLab 6: Why Many Americans Don‚Äôt Vote\n\n\n\nüíª\n\n\n\n\n\n\nTue, Apr 5\nMultiLR: Prediction + inferential models\nüìñ\nüñ•Ô∏è\n\n\n\n\n\n\n\n\nThu, Apr 7\nMultiLR: Predictive models\n\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\nFri, Apr 8\nDue: Lab 6\n\n\n\nüíª üóùÔ∏è\n\n\n\n\n\n\nSun, Apr 10\nDue: Project drafts\n\n\n\n\n\n\nüìÇ\n\n\n14\nMon, Apr 11\nLab: Project peer review of drafts\n\n\n\n\n\n\nüìÇ\n\n\n\nTue, Apr 12\nMultiLR: Predictive models (cont.)\nüìñ\nüñ•Ô∏è\n\n\n\n\n\n\n\n\n\nDue: HW 4\n\n\n\n\n‚úçÔ∏è üóùÔ∏è\n\n\n\n\n\nThu, Apr 14\nExam 3 review\n\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\n\nDue: Peer review\n\n\n\n\n\n\nüìÇ\n\n\n\nFri, Apr 15\nReleased: Exam 3\n\n\n\n\n\n‚úÖ\n\n\n\n15\nMon, Apr 18\nNo lab: Work on Exam 3\n\n\n\n\n\n\n\n\n\n\n\nDue: Exam 3\n\n\n\n\n\n‚úÖ\n\n\n\n\nTue, Apr 19\nWrap-up\nüìñ\nüñ•Ô∏è\nüìã\n\n\n\n\n\n\n\n\nDue: HW 5\n\n\n\n\n‚úçÔ∏è\n\n\n\n\n16\nMon, Apr 25\nDue: Project write-up\n\n\n\n\n\n\nüìÇ\n\n\n\nThu, Apr 28\nDue: Video presentation + repo\n\n\n\n\n\n\nüìÇ\n\n\n\nSat, Apr 30\nDue: Video comments\n\n\n\n\n\n\nüìÇ"
  },
  {
    "objectID": "weeks/week-9.html",
    "href": "weeks/week-9.html",
    "title": "Week 9",
    "section": "",
    "text": "Important\n\n\n\nDue date: Exam 1 released on Fri, Feb 35, due Mon, Feb 28 at 11:59pm"
  },
  {
    "objectID": "weeks/week-9.html#prepare",
    "href": "weeks/week-9.html#prepare",
    "title": "Week 9",
    "section": "Prepare",
    "text": "Prepare\nNo readings this week."
  },
  {
    "objectID": "weeks/week-9.html#participate",
    "href": "weeks/week-9.html#participate",
    "title": "Week 9",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lecture 16 - MLR: Inference\nüñ•Ô∏è Lecture 17 - MLR: Inference conditions + multicollinearity"
  },
  {
    "objectID": "weeks/week-9.html#practice",
    "href": "weeks/week-9.html#practice",
    "title": "Week 9",
    "section": "Practice",
    "text": "Practice\nüìã Application Exercise 8 - Rail Trail"
  },
  {
    "objectID": "weeks/week-9.html#perform",
    "href": "weeks/week-9.html#perform",
    "title": "Week 9",
    "section": "Perform",
    "text": "Perform\n‚úÖ Exam 2\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-7.html",
    "href": "weeks/week-7.html",
    "title": "Week 7",
    "section": "",
    "text": "Important\n\n\n\nDue dates:\n\nHW 2 - Friday, Feb 18\nProject ideas - Friday, Feb 18"
  },
  {
    "objectID": "weeks/week-7.html#prepare",
    "href": "weeks/week-7.html#prepare",
    "title": "Week 7",
    "section": "Prepare",
    "text": "Prepare\nüìñ Read Tidy Modeling in R Chp 8: Feature engineering with recipes"
  },
  {
    "objectID": "weeks/week-7.html#participate",
    "href": "weeks/week-7.html#participate",
    "title": "Week 7",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lecture 12 - MLR: Feature engineering\nüñ•Ô∏è Lecture 13 - MLR: Feature engineering (cont.)"
  },
  {
    "objectID": "weeks/week-7.html#practice",
    "href": "weeks/week-7.html#practice",
    "title": "Week 7",
    "section": "Practice",
    "text": "Practice\nüìã Application Exercise 5 - The Office"
  },
  {
    "objectID": "weeks/week-7.html#perform",
    "href": "weeks/week-7.html#perform",
    "title": "Week 7",
    "section": "Perform",
    "text": "Perform\n‚úçÔ∏è HW 2 - Multiple linear regression\nüìÇ Project - Topic ideas\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-5.html",
    "href": "weeks/week-5.html",
    "title": "Week 5",
    "section": "",
    "text": "Important\n\n\n\n\nDue date: Lab 2 - Fri, Feb 4, 5pm ET\nExam 1 released on Fri, Feb 4, due Mon, Feb 7 at 11:59pm"
  },
  {
    "objectID": "weeks/week-5.html#prepare",
    "href": "weeks/week-5.html#prepare",
    "title": "Week 5",
    "section": "Prepare",
    "text": "Prepare\nüìñ Read Introduction to Modern Statistics, Sec 8.1: Indicator and categorical predictors\nüìñ Read Introduction to Modern Statistics, Sec 8.2: Many predictors in a model\nüìñ Read Introduction to Modern Statistics, Sec 8.3: Adjusted R-squared"
  },
  {
    "objectID": "weeks/week-5.html#participate",
    "href": "weeks/week-5.html#participate",
    "title": "Week 5",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lab 3 - Coffee ratings\nüñ•Ô∏è Lecture 8 - Multiple linear regression (MLR)\nüñ•Ô∏è Lecture 9 - Exam 1 review"
  },
  {
    "objectID": "weeks/week-5.html#practice",
    "href": "weeks/week-5.html#practice",
    "title": "Week 5",
    "section": "Practice",
    "text": "Practice\nüìã Application Exercise 4 - Exam 1 Review"
  },
  {
    "objectID": "weeks/week-5.html#perform",
    "href": "weeks/week-5.html#perform",
    "title": "Week 5",
    "section": "Perform",
    "text": "Perform\n‚å®Ô∏è Lab 3 - Coffee ratings\n‚úÖ Exam 1\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-3.html",
    "href": "weeks/week-3.html",
    "title": "Week 3",
    "section": "",
    "text": "Important\n\n\n\n\nWe‚Äôre back to in person classes this week! See here for class locations. And don‚Äôt forget to wear your mask! üò∑\nDue dates:\n\nAE 2: Fri, Jan 21, 11:59pm ET"
  },
  {
    "objectID": "weeks/week-3.html#prepare",
    "href": "weeks/week-3.html#prepare",
    "title": "Week 3",
    "section": "Prepare",
    "text": "Prepare\nüìñ Read Introduction to Modern Statistics, Sec 24.1: Case study: Sandwich store\nüìñ Read Introduction to Modern Statistics, Sec 24.2: Randomization test for the slope\nüìñ Read Introduction to Modern Statistics, Sec 24.3: Bootstrap confidence interval for the slope"
  },
  {
    "objectID": "weeks/week-3.html#participate",
    "href": "weeks/week-3.html#participate",
    "title": "Week 3",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lecture 4 - SLR: Prediction + model evaluation\nüñ•Ô∏è Lecture 5 - SLR: Simulation-based inference"
  },
  {
    "objectID": "weeks/week-3.html#practice",
    "href": "weeks/week-3.html#practice",
    "title": "Week 3",
    "section": "Practice",
    "text": "Practice\nüìã Application Exercise 2 - Bike rentals in DC"
  },
  {
    "objectID": "weeks/week-3.html#perform",
    "href": "weeks/week-3.html#perform",
    "title": "Week 3",
    "section": "Perform",
    "text": "Perform\nNone.\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-15.html",
    "href": "weeks/week-15.html",
    "title": "Week 15",
    "section": "",
    "text": "Important\n\n\n\nDue dates: Tue, Apr 19 - HW 5"
  },
  {
    "objectID": "weeks/week-15.html#participate",
    "href": "weeks/week-15.html#participate",
    "title": "Week 15",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lecture 28 - Wrap up"
  },
  {
    "objectID": "weeks/week-15.html#practice",
    "href": "weeks/week-15.html#practice",
    "title": "Week 15",
    "section": "Practice",
    "text": "Practice\nüìã Application Exercise 13 - A Tale of Two Creeks"
  },
  {
    "objectID": "weeks/week-15.html#perform",
    "href": "weeks/week-15.html#perform",
    "title": "Week 15",
    "section": "Perform",
    "text": "Perform\n‚úçÔ∏è HW 5 - Statistics experience\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-13.html",
    "href": "weeks/week-13.html",
    "title": "Week 13",
    "section": "",
    "text": "Important\n\n\n\nDue dates:\n\nLab 6 - Friday, April 8\nProject drafts - Sunday, April 10"
  },
  {
    "objectID": "weeks/week-13.html#participate",
    "href": "weeks/week-13.html#participate",
    "title": "Week 13",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lecture 24 - MultiLR: Prediction + inferential models\nüñ•Ô∏è Lecture 25 - MultiLR: Predictive models"
  },
  {
    "objectID": "weeks/week-13.html#practice",
    "href": "weeks/week-13.html#practice",
    "title": "Week 13",
    "section": "Practice",
    "text": "Practice\nüìã Application Exercise 11 - Volcanoes"
  },
  {
    "objectID": "weeks/week-13.html#perform",
    "href": "weeks/week-13.html#perform",
    "title": "Week 13",
    "section": "Perform",
    "text": "Perform\n‚úçÔ∏è HW 4 - Multinomial logistic regression\nüíª Lab 6 - Why Many Americans Don‚Äôt Vote\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-11.html",
    "href": "weeks/week-11.html",
    "title": "Week 11",
    "section": "",
    "text": "Important\n\n\n\nDue dates:\n\nLab 5 - Friday, Mar 25\nHW 3 - Friday, Mar 25"
  },
  {
    "objectID": "weeks/week-11.html#prepare",
    "href": "weeks/week-11.html#prepare",
    "title": "Week 11",
    "section": "Prepare",
    "text": "Prepare\nNo additional readings this week. Catch up with previously assigned readings if you‚Äôve fallen behind."
  },
  {
    "objectID": "weeks/week-11.html#participate",
    "href": "weeks/week-11.html#participate",
    "title": "Week 11",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lecture 20 - LR: Prediction / classification\nüñ•Ô∏è Lecture 21 - LR: Model validation"
  },
  {
    "objectID": "weeks/week-11.html#practice",
    "href": "weeks/week-11.html#practice",
    "title": "Week 11",
    "section": "Practice",
    "text": "Practice\nüìã Application Exercise 10 - Flight delays"
  },
  {
    "objectID": "weeks/week-11.html#perform",
    "href": "weeks/week-11.html#perform",
    "title": "Week 11",
    "section": "Perform",
    "text": "Perform\n‚úçÔ∏è HW 3 - Logistic regression and log transformation\n‚å®Ô∏è Lab 5 - General Social Survey\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-1.html",
    "href": "weeks/week-1.html",
    "title": "Week 1",
    "section": "",
    "text": "Important\n\n\n\nClasses are virtual this week. Find Zoom links here."
  },
  {
    "objectID": "weeks/week-1.html#prepare",
    "href": "weeks/week-1.html#prepare",
    "title": "Week 1",
    "section": "Prepare",
    "text": "Prepare\nüìñ Read the syllabus\nüìñ Read the support resources"
  },
  {
    "objectID": "weeks/week-1.html#participate",
    "href": "weeks/week-1.html#participate",
    "title": "Week 1",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lab 0 -Meet+ greet\nüñ•Ô∏è Lecture 1 - Welcome to STA 210"
  },
  {
    "objectID": "weeks/week-1.html#practice",
    "href": "weeks/week-1.html#practice",
    "title": "Week 1",
    "section": "Practice",
    "text": "Practice\nüìã AE 0 - Movies"
  },
  {
    "objectID": "weeks/week-1.html#perform",
    "href": "weeks/week-1.html#perform",
    "title": "Week 1",
    "section": "Perform",
    "text": "Perform\n‚å®Ô∏è Lab 0 - Meet + greet\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "supplemental/model-selection-criteria.html",
    "href": "supplemental/model-selection-criteria.html",
    "title": "Model Selection Criteria: AIC & BIC",
    "section": "",
    "text": "Note\n\n\n\nThe following supplemental notes were created by Dr.¬†Maria Tackett for STA 210. They are provided for students who want to dive deeper into the mathematics behind regression and reflect some of the material covered in STA 211: Mathematics of Regression. Additional supplemental notes will be added throughout the semester.\nThis document discusses some of the mathematical details of Akaike‚Äôs Information Criterion (AIC) and Schwarz‚Äôs Bayesian Information Criterion (BIC). We assume the reader knowledge of the matrix form for multiple linear regression.Please see Matrix Notation for Multiple Linear Regression for a review."
  },
  {
    "objectID": "supplemental/model-selection-criteria.html#maximum-likelihood-estimation-of-boldsymbolbeta-and-sigma",
    "href": "supplemental/model-selection-criteria.html#maximum-likelihood-estimation-of-boldsymbolbeta-and-sigma",
    "title": "Model Selection Criteria: AIC & BIC",
    "section": "Maximum Likelihood Estimation of \\(\\boldsymbol{\\beta}\\) and \\(\\sigma\\)",
    "text": "Maximum Likelihood Estimation of \\(\\boldsymbol{\\beta}\\) and \\(\\sigma\\)\nTo understand the formulas for AIC and BIC, we will first briefly explain the likelihood function and maximum likelihood estimates for regression.\nLet \\(\\mathbf{Y}\\) be \\(n \\times 1\\) matrix of responses, \\(\\mathbf{X}\\), the \\(n \\times (p+1)\\) matrix of predictors, and \\(\\boldsymbol{\\beta}\\), \\((p+1) \\times 1\\) matrix of coefficients. If the multiple linear regression model is correct then,\n\\[\n\\mathbf{Y} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma^2)\n\\tag{1}\\]\nWhen we do linear regression, our goal is to estimate the unknown parameters \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\) from Equation¬†1. In Matrix Notation for Multiple Linear Regression, we showed a way to estimate these parameters using matrix alegbra. Another approach for estimating \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\) is using maximum likelihood estimation.\nA likelihood function is used to summarise the evidence from the data in support of each possible value of a model parameter. Using Equation¬†1, we will write the likelihood function for linear regression as\n\\[\nL(\\mathbf{X}, \\mathbf{Y}|\\boldsymbol{\\beta}, \\sigma^2) = \\prod\\limits_{i=1}^n (2\\pi \\sigma^2)^{-\\frac{1}{2}} \\exp\\bigg\\{-\\frac{1}{2\\sigma^2}\\sum\\limits_{i=1}^n(Y_i - \\mathbf{X}_i \\boldsymbol{\\beta})^T(Y_i - \\mathbf{X}_i \\boldsymbol{\\beta})\\bigg\\}\n\\tag{2}\\]\nwhere \\(Y_i\\) is the \\(i^{th}\\) response and \\(\\mathbf{X}_i\\) is the vector of predictors for the \\(i^{th}\\) observation. One approach estimating \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\) is to find the values of those parameters that maximize the likelihood in Equation¬†2, i.e.¬†maximum likelhood estimation. To make the calculations more manageable, instead of maximizing the likelihood function, we will instead maximize its logarithm, i.e.¬†the log-likelihood function. The values of the parameters that maximize the log-likelihood function are those that maximize the likelihood function. The log-likelihood function we will maximize is\n\\[\n\\begin{aligned}\n\\log L(\\mathbf{X}, \\mathbf{Y}|\\boldsymbol{\\beta}, \\sigma^2) &= \\sum\\limits_{i=1}^n -\\frac{1}{2}\\log(2\\pi\\sigma^2) -\\frac{1}{2\\sigma^2}\\sum\\limits_{i=1}^n(Y_i - \\mathbf{X}_i \\boldsymbol{\\beta})^T(Y_i - \\mathbf{X}_i \\boldsymbol{\\beta}) \\\\\n&= -\\frac{n}{2}\\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})^T(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})\\\\\n\\end{aligned}\n\\tag{3}\\]\n\nThe maximum likelihood estimate of \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\) are \\[\n\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y} \\hspace{10mm} \\hat{\\sigma}^2 = \\frac{1}{n}(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})^T(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta}) = \\frac{1}{n}RSS\n\\tag{4}\\]\nwhere \\(RSS\\) is the residual sum of squares. Note that the maximum likelihood estimate is not exactly equal to the estimate of \\(\\sigma^2\\) we typically use \\(\\frac{RSS}{n-p-1}\\). This is because the maximum likelihood estimate of \\(\\sigma^2\\) in Equation¬†4 is a biased estimator of \\(\\sigma^2\\). When \\(n\\) is much larger than the number of predictors \\(p\\), then the differences in these two estimates are trivial."
  },
  {
    "objectID": "supplemental/model-selection-criteria.html#aic",
    "href": "supplemental/model-selection-criteria.html#aic",
    "title": "Model Selection Criteria: AIC & BIC",
    "section": "AIC",
    "text": "AIC\nAkaike‚Äôs Information Criterion (AIC) is\n\\[\nAIC = -2 \\log L + 2(p+1)\n\\tag{5}\\]\nwhere \\(\\log L\\) is the log-likelihood. This is the general form of AIC that can be applied to a variety of models, but for now, let‚Äôs focus on AIC for mutliple linear regression.\n\\[\n\\begin{aligned}\nAIC &= -2 \\log L + 2(p+1) \\\\\n&= -2\\bigg[-\\frac{n}{2}\\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})^T(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})\\bigg] + 2(p+1) \\\\\n&= n\\log\\big(2\\pi\\frac{RSS}{n}\\big) + \\frac{1}{RSS/n}RSS \\\\\n&= n\\log(2\\pi) + n\\log(RSS) - n\\log(n) + 2(p+1)\n\\end{aligned}\n\\tag{6}\\]"
  },
  {
    "objectID": "supplemental/model-selection-criteria.html#bic",
    "href": "supplemental/model-selection-criteria.html#bic",
    "title": "Model Selection Criteria: AIC & BIC",
    "section": "BIC",
    "text": "BIC\n[To be added.]"
  },
  {
    "objectID": "supplemental/mlr-matrix.html",
    "href": "supplemental/mlr-matrix.html",
    "title": "Matrix Notation for Multiple Linear Regression",
    "section": "",
    "text": "Note\n\n\n\nThe following supplemental notes were created by Dr.¬†Maria Tackett for STA 210. They are provided for students who want to dive deeper into the mathematics behind regression and reflect some of the material covered in STA 211: Mathematics of Regression. Additional supplemental notes will be added throughout the semester.\nThis document provides the details for the matrix notation for multiple linear regression. We assume the reader has familiarity with some linear algebra. Please see Chapter 1 of An Introduction to Statistical Learning for a brief review of linear algebra."
  },
  {
    "objectID": "supplemental/mlr-matrix.html#introduction",
    "href": "supplemental/mlr-matrix.html#introduction",
    "title": "Matrix Notation for Multiple Linear Regression",
    "section": "Introduction",
    "text": "Introduction\nSuppose we have \\(n\\) observations. Let the \\(i^{th}\\) be \\((x_{i1}, \\ldots, x_{ip}, y_i)\\), such that \\(x_{i1}, \\ldots, x_{ip}\\) are the explanatory variables (predictors) and \\(y_i\\) is the response variable. We assume the data can be modeled using the least-squares regression model, such that the mean response for a given combination of explanatory variables follows the form in Equation¬†1.\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p\n\\tag{1}\\]\nWe can write the response for the \\(i^{th}\\) observation as shown in Equation¬†2\n\\[\ny_i = \\beta_0 + \\beta_1 x_{i1} + \\dots + \\beta_p x_{ip} + \\epsilon_i\n\\tag{2}\\]\nsuch that \\(\\epsilon_i\\) is the amount \\(y_i\\) deviates from \\(\\mu\\{y|x_{i1}, \\ldots, x_{ip}\\}\\), the mean response for a given combination of explanatory variables. We assume each \\(\\epsilon_i \\sim N(0,\\sigma^2)\\), where \\(\\sigma^2\\) is a constant variance for the distribution of the response \\(y\\) for any combination of explanatory variables \\(x_1, \\ldots, x_p\\)."
  },
  {
    "objectID": "supplemental/mlr-matrix.html#matrix-representation-for-the-regression-model",
    "href": "supplemental/mlr-matrix.html#matrix-representation-for-the-regression-model",
    "title": "Matrix Notation for Multiple Linear Regression",
    "section": "Matrix Representation for the Regression Model",
    "text": "Matrix Representation for the Regression Model\nWe can represent the Equation¬†1 and Equation¬†2 using matrix notation. Let\n\\[\n\\mathbf{Y} = \\begin{bmatrix}y_1 \\\\ y_2 \\\\ \\vdots \\\\y_n\\end{bmatrix}\n\\hspace{15mm}\n\\mathbf{X} = \\begin{bmatrix}x_{11} & x_{12} & \\dots & x_{1p} \\\\\nx_{21} & x_{22} & \\dots & x_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\nx_{n1} & x_{n2} & \\dots & x_{np} \\end{bmatrix}\n\\hspace{15mm}\n\\boldsymbol{\\beta}= \\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\\\ \\vdots \\\\ \\beta_p \\end{bmatrix}\n\\hspace{15mm}\n\\boldsymbol{\\epsilon}= \\begin{bmatrix}\\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{bmatrix}\n\\tag{3}\\]\nThus,\n\\[\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\\]\nTherefore the estimated response for a given combination of explanatory variables and the associated residuals can be written as\n\\[\n\\hat{\\mathbf{Y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\hspace{10mm} \\mathbf{e} = \\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\n\\tag{4}\\]"
  },
  {
    "objectID": "supplemental/mlr-matrix.html#estimating-the-coefficients",
    "href": "supplemental/mlr-matrix.html#estimating-the-coefficients",
    "title": "Matrix Notation for Multiple Linear Regression",
    "section": "Estimating the Coefficients",
    "text": "Estimating the Coefficients\nThe least-squares model is the one that minimizes the sum of the squared residuals. Therefore, we want to find the coefficients, \\(\\hat{\\boldsymbol{\\beta}}\\) that minimizes\n\\[\n\\sum\\limits_{i=1}^{n} e_{i}^2 = \\mathbf{e}^T\\mathbf{e} = (\\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}})^T(\\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}})\n\\tag{5}\\]\nwhere \\(\\mathbf{e}^T\\), the transpose of the matrix \\(\\mathbf{e}\\).\n\\[\n(\\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}})^T(\\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}) = (\\mathbf{Y}^T\\mathbf{Y} -\n\\mathbf{Y}^T \\mathbf{X}\\hat{\\boldsymbol{\\beta}} - (\\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{Y} +\n\\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{X}\n\\hat{\\boldsymbol{\\beta}})\n\\tag{6}\\]\nNote that \\((\\mathbf{Y^T}\\mathbf{X}\\hat{\\boldsymbol{\\beta}})^T = \\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{Y}\\). Since these are both constants (i.e.¬†\\(1\\times 1\\) vectors), \\(\\mathbf{Y^T}\\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{Y}\\). Thus, Equation¬†7 becomes\n\\[\n\\mathbf{Y}^T\\mathbf{Y} - 2 \\mathbf{X}^T\\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{Y} + \\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{X}\n\\hat{\\boldsymbol{\\beta}}\n\\tag{7}\\]\nSince we want to find the \\(\\hat{\\boldsymbol{\\beta}}\\) that minimizes Equation¬†5, will find the value of \\(\\hat{\\boldsymbol{\\beta}}\\) such that the derivative with respect to \\(\\hat{\\boldsymbol{\\beta}}\\) is equal to 0.\n\\[\n\\begin{aligned}\n\\frac{\\partial \\mathbf{e}^T\\mathbf{e}}{\\partial \\hat{\\boldsymbol{\\beta}}} & = \\frac{\\partial}{\\partial \\hat{\\boldsymbol{\\beta}}}(\\mathbf{Y}^T\\mathbf{Y} - 2 \\mathbf{X}^T\\hat{\\boldsymbol{\\beta}}{}^T\\mathbf{Y} + \\hat{\\boldsymbol{\\beta}}{}^{T}\\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}}) = 0 \\\\\n&\\Rightarrow - 2 \\mathbf{X}^T\\mathbf{Y} + 2 \\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} = 0 \\\\\n& \\Rightarrow 2 \\mathbf{X}^T\\mathbf{Y} = 2 \\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\\n& \\Rightarrow \\mathbf{X}^T\\mathbf{Y} = \\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\\n& \\Rightarrow (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\\n& \\Rightarrow (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y} = \\mathbf{I}\\hat{\\boldsymbol{\\beta}}\n\\end{aligned}\n\\tag{8}\\]\nThus, the estimate of the model coefficients is \\(\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}\\)."
  },
  {
    "objectID": "supplemental/mlr-matrix.html#variance-covariance-matrix-of-the-coefficients",
    "href": "supplemental/mlr-matrix.html#variance-covariance-matrix-of-the-coefficients",
    "title": "Matrix Notation for Multiple Linear Regression",
    "section": "Variance-covariance matrix of the coefficients",
    "text": "Variance-covariance matrix of the coefficients\nWe will use two properties to derive the form of the variance-covariance matrix of the coefficients:\n\n\\(E[\\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T] = \\sigma^2I\\)\n\\(\\hat{\\boldsymbol{\\beta}} = \\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1}\\epsilon\\)\n\nFirst, we will show that \\(E[\\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T] = \\sigma^2I\\)\n\\[\n\\begin{aligned}\nE[\\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T] &= E \\begin{bmatrix}\\epsilon_1  & \\epsilon_2 & \\dots & \\epsilon_n \\end{bmatrix}\\begin{bmatrix}\\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{bmatrix}  \\\\\n& = E \\begin{bmatrix} \\epsilon_1^2  & \\epsilon_1 \\epsilon_2 & \\dots & \\epsilon_1 \\epsilon_n \\\\\n\\epsilon_2 \\epsilon_1 & \\epsilon_2^2 & \\dots & \\epsilon_2 \\epsilon_n \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\epsilon_n \\epsilon_1 & \\epsilon_n \\epsilon_2 & \\dots & \\epsilon_n^2\n\\end{bmatrix} \\\\\n& = \\begin{bmatrix} E[\\epsilon_1^2]  & E[\\epsilon_1 \\epsilon_2] & \\dots & E[\\epsilon_1 \\epsilon_n] \\\\\nE[\\epsilon_2 \\epsilon_1] & E[\\epsilon_2^2] & \\dots & E[\\epsilon_2 \\epsilon_n] \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nE[\\epsilon_n \\epsilon_1] & E[\\epsilon_n \\epsilon_2] & \\dots & E[\\epsilon_n^2]\n\\end{bmatrix}\n\\end{aligned}\n\\tag{9}\\]\nRecall, the regression assumption that the errors \\(\\epsilon_i's\\) are Normally distributed with mean 0 and variance \\(\\sigma^2\\). Thus, \\(E(\\epsilon_i^2) = Var(\\epsilon_i) = \\sigma^2\\) for all \\(i\\). Additionally, recall the regression assumption that the errors are uncorrelated, i.e.¬†\\(E(\\epsilon_i \\epsilon_j) = Cov(\\epsilon_i, \\epsilon_j) = 0\\) for all \\(i,j\\). Using these assumptions, we can write Equation¬†9 as\n\\[\nE[\\mathbf{\\epsilon}\\mathbf{\\epsilon}^T]  = \\begin{bmatrix} \\sigma^2  & 0 & \\dots & 0 \\\\\n0 & \\sigma^2  & \\dots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\dots & \\sigma^2\n\\end{bmatrix} = \\sigma^2 \\mathbf{I}\n\\tag{10}\\]\nwhere \\(\\mathbf{I}\\) is the \\(n \\times n\\) identity matrix.\nNext, we show that \\(\\hat{\\boldsymbol{\\beta}} = \\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1}\\epsilon\\).\nRecall that the \\(\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}\\) and \\(\\mathbf{Y} = \\mathbf{X}\\mathbf{\\beta} + \\mathbf{\\epsilon}\\). Then,\n\\[\n\\begin{aligned}\n\\hat{\\boldsymbol{\\beta}} &= (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y} \\\\\n&= (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T(\\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}) \\\\\n&= \\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T \\mathbf{\\epsilon} \\\\\n\\end{aligned}\n\\tag{11}\\]\nUsing these two properties, we derive the form of the variance-covariance matrix for the coefficients. Note that the covariance matrix is \\(E[(\\hat{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})(\\hat{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})^T]\\)\n\\[\n\\begin{aligned}\nE[(\\hat{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})(\\hat{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})^T] &= E[(\\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T \\boldsymbol{\\epsilon} - \\boldsymbol{\\beta})(\\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T \\boldsymbol{\\epsilon} - \\boldsymbol{\\beta})^T]\\\\\n& = E[(\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T \\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}] \\\\\n& = (\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T E[\\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T]\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\\\\n& = (\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T (\\sigma^2\\mathbf{I})\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\\\\n&= \\sigma^2\\mathbf{I}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\\\\n& = \\sigma^2\\mathbf{I}(\\mathbf{X}^T\\mathbf{X})^{-1}\\\\\n&  = \\sigma^2(\\mathbf{X}^T\\mathbf{X})^{-1} \\\\\n\\end{aligned}\n\\tag{12}\\]"
  },
  {
    "objectID": "slides/lec-9.html",
    "href": "slides/lec-9.html",
    "title": "Exam 1 Review",
    "section": "",
    "text": "Lab 3 due tomorrow (Friday) at 5pm on Gradescope, one submission per team\nExam 1 open tomorrow (Friday) at 9am and ends on Monday, Feb 7 at 11:59pm\nNo lab on Monday, take the time to work on your exam"
  },
  {
    "objectID": "slides/lec-9.html#announcements",
    "href": "slides/lec-9.html#announcements",
    "title": "Exam 1 Review",
    "section": "",
    "text": "Lab 3 due tomorrow (Friday) at 5pm on Gradescope, one submission per team\nExam 1 open tomorrow (Friday) at 9am and ends on Monday, Feb 7 at 11:59pm\nNo lab on Monday, take the time to work on your exam"
  },
  {
    "objectID": "slides/lec-9.html#feedback-from-submissions-so-far",
    "href": "slides/lec-9.html#feedback-from-submissions-so-far",
    "title": "Exam 1 Review",
    "section": "Feedback from submissions so far",
    "text": "Feedback from submissions so far\n\nYou must submit a PDF (not HTML) to Gradescope\nYou must tag your pages when you upload to Gradescope ‚Äì if you don‚Äôt know how to do this, please ask well before the deadline!\nYou must not refer to keys distributed in previous semesters of the course ‚Äì much of what we‚Äôre doing is different and some of it is the same. If you need help, please ask!"
  },
  {
    "objectID": "slides/lec-9.html#exam-1",
    "href": "slides/lec-9.html#exam-1",
    "title": "Exam 1 Review",
    "section": "Exam 1",
    "text": "Exam 1\n\nInstructions can be found at\nCovers everything we‚Äôve done so far\nOffice hours:\n\nTomorrow‚Äôs TA office hours are only for Lab 3 questions\nMonday: I have office hours 10:30-11:30am\n\nAny clarification questions for the exam?\n\nDirect message me or Rick on Slack\nPost on Sakai Conversations, post to ‚ÄúInstructors in this site‚Äù"
  },
  {
    "objectID": "slides/lec-9.html#application-exercise",
    "href": "slides/lec-9.html#application-exercise",
    "title": "Exam 1 Review",
    "section": "Application Exercise",
    "text": "Application Exercise\n\nüìã github.com/sta210-s22/ae-4-exam-1-review"
  },
  {
    "objectID": "slides/lec-7.html",
    "href": "slides/lec-7.html",
    "title": "SLR: Model diagnostics",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(openintro)   # for the duke_forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(knitr)       # for pretty tables\nlibrary(kableExtra)  # also for pretty tables\nlibrary(patchwork)   # arrange plots\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 20))"
  },
  {
    "objectID": "slides/lec-7.html#computational-setup",
    "href": "slides/lec-7.html#computational-setup",
    "title": "SLR: Model diagnostics",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(openintro)   # for the duke_forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(knitr)       # for pretty tables\nlibrary(kableExtra)  # also for pretty tables\nlibrary(patchwork)   # arrange plots\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 20))"
  },
  {
    "objectID": "slides/lec-7.html#the-regression-model-revisited",
    "href": "slides/lec-7.html#the-regression-model-revisited",
    "title": "SLR: Model diagnostics",
    "section": "The regression model, revisited",
    "text": "The regression model, revisited\n\ndf_fit &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) %&gt;%\n  kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "slides/lec-7.html#ht-for-the-slope",
    "href": "slides/lec-7.html#ht-for-the-slope",
    "title": "SLR: Model diagnostics",
    "section": "HT for the slope",
    "text": "HT for the slope\nHypotheses: \\(H_0: \\beta_1 = 0\\) vs.¬†\\(H_A: \\beta_1 \\ne 0\\)\n. . .\nTest statistic: Number of standard errors the estimate is away from the null\n\\[\nT = \\frac{\\text{Estimate - Null}}{\\text{Standard error}} \\\\\n\\]\n. . .\np-value: Probability of observing a test statistic at least as extreme (in the direction of the alternative hypothesis) from the null value as the one observed\n\\[\np-value = P(|t| &gt; |\\text{test statistic}),\n\\]\ncalculated from a \\(t\\) distribution with \\(n - 2\\) degrees of freedom"
  },
  {
    "objectID": "slides/lec-7.html#ht-test-statistic",
    "href": "slides/lec-7.html#ht-test-statistic",
    "title": "SLR: Model diagnostics",
    "section": "HT: Test statistic",
    "text": "HT: Test statistic\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\n\\[\nt = \\frac{\\hat{\\beta}_1 - 0}{SE_{\\hat{\\beta}_1}} = \\frac{159.48 - 0}{18.17} = 8.78\n\\]"
  },
  {
    "objectID": "slides/lec-7.html#ht-p-value",
    "href": "slides/lec-7.html#ht-p-value",
    "title": "SLR: Model diagnostics",
    "section": "HT: p-value",
    "text": "HT: p-value\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "slides/lec-7.html#understanding-the-p-value",
    "href": "slides/lec-7.html#understanding-the-p-value",
    "title": "SLR: Model diagnostics",
    "section": "Understanding the p-value",
    "text": "Understanding the p-value\n\n\n\nMagnitude of p-value\nInterpretation\n\n\n\n\np-value &lt; 0.01\nstrong evidence against \\(H_0\\)\n\n\n0.01 &lt; p-value &lt; 0.05\nmoderate evidence against \\(H_0\\)\n\n\n0.05 &lt; p-value &lt; 0.1\nweak evidence against \\(H_0\\)\n\n\np-value &gt; 0.1\neffectively no evidence against \\(H_0\\)\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThese are general guidelines. The strength of evidence depends on the context of the problem."
  },
  {
    "objectID": "slides/lec-7.html#ht-conclusion-in-context",
    "href": "slides/lec-7.html#ht-conclusion-in-context",
    "title": "SLR: Model diagnostics",
    "section": "HT: Conclusion, in context",
    "text": "HT: Conclusion, in context\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\n\nThe data provide convincing evidence that the population slope \\(\\beta_1\\) is different from 0.\nThe data provide convincing evidence of a linear relationship between area and price of houses in Duke Forest."
  },
  {
    "objectID": "slides/lec-7.html#ci-for-the-slope",
    "href": "slides/lec-7.html#ci-for-the-slope",
    "title": "SLR: Model diagnostics",
    "section": "CI for the slope",
    "text": "CI for the slope\n\\[\n\\text{Estimate} \\pm \\text{ (critical value) } \\times \\text{SE}\n\\]\n. . .\n\\[\n\\hat{\\beta}_1 \\pm t^* \\times SE_{\\hat{\\beta}_1}\n\\]\nwhere \\(t^*\\) is calculated from a \\(t\\) distribution with \\(n-2\\) degrees of freedom"
  },
  {
    "objectID": "slides/lec-7.html#ci-critical-value",
    "href": "slides/lec-7.html#ci-critical-value",
    "title": "SLR: Model diagnostics",
    "section": "CI: Critical value",
    "text": "CI: Critical value\n\n\n\n# confidence level: 95%\nqt(0.975, df = nrow(duke_forest) - 2)\n\n[1] 1.984984\n\n# confidence level: 90%\nqt(0.95, df = nrow(duke_forest) - 2)\n\n[1] 1.660881\n\n# confidence level: 99%\nqt(0.995, df = nrow(duke_forest) - 2)\n\n[1] 2.628016"
  },
  {
    "objectID": "slides/lec-7.html#ci-for-the-slope-calculation",
    "href": "slides/lec-7.html#ci-for-the-slope-calculation",
    "title": "SLR: Model diagnostics",
    "section": "95% CI for the slope: Calculation",
    "text": "95% CI for the slope: Calculation\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\n\\[\\hat{\\beta}_1 = 159.48 \\hspace{15mm} t^* = 1.98 \\hspace{15mm} SE_{\\hat{\\beta}_1} = 18.17\\]\n. . .\n\\[\n159.48 \\pm 1.98 \\times 18.17 = (123.50, 195.46)\n\\]"
  },
  {
    "objectID": "slides/lec-7.html#ci-for-the-slope-computation",
    "href": "slides/lec-7.html#ci-for-the-slope-computation",
    "title": "SLR: Model diagnostics",
    "section": "95% CI for the slope: Computation",
    "text": "95% CI for the slope: Computation\n\ntidy(df_fit, conf.int = TRUE, conf.level = 0.95) %&gt;% \n  kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n10847.77\n222456.88\n\n\narea\n159.48\n18.17\n8.78\n0.00\n123.41\n195.55"
  },
  {
    "objectID": "slides/lec-7.html#confidence-interval-for-predictions",
    "href": "slides/lec-7.html#confidence-interval-for-predictions",
    "title": "SLR: Model diagnostics",
    "section": "Confidence interval for predictions",
    "text": "Confidence interval for predictions\n\nSuppose we want to answer the question ‚ÄúWhat is the predicted sale price of a Duke Forest house that is 2,800 square feet?‚Äù\nWe said reporting a single estimate for the slope is not wise, and we should report a plausible range instead\nSimilarly, reporting a single prediction for a new value is not wise, and we should report a plausible range instead"
  },
  {
    "objectID": "slides/lec-7.html#two-types-of-predictions",
    "href": "slides/lec-7.html#two-types-of-predictions",
    "title": "SLR: Model diagnostics",
    "section": "Two types of predictions",
    "text": "Two types of predictions\n\nPrediction for the mean: ‚Äú‚ÄúWhat is the average predicted sale price of Duke Forest houses that are 2,800 square feet?‚Äù\nPrediction for an individual observation: ‚ÄúWhat is the predicted sale price of a Duke Forest house that is 2,800 square feet?‚Äù\n\n. . .\n\nWhich would you expect to be more variable? The average prediction or the prediction for an individual observation? Based on your answer, how would you expect the widths of plausible ranges for these two predictions to compare?"
  },
  {
    "objectID": "slides/lec-7.html#uncertainty-in-predictions",
    "href": "slides/lec-7.html#uncertainty-in-predictions",
    "title": "SLR: Model diagnostics",
    "section": "Uncertainty in predictions",
    "text": "Uncertainty in predictions\nConfidence interval for the mean outcome: \\[\\hat{y} \\pm t_{n-2}^* \\times \\color{purple}{\\mathbf{SE}_{\\hat{\\boldsymbol{\\mu}}}}\\]\n. . .\nPrediction interval for an individual observation: \\[\\hat{y} \\pm t_{n-2}^* \\times \\color{purple}{\\mathbf{SE_{\\hat{y}}}}\\]"
  },
  {
    "objectID": "slides/lec-7.html#standard-errors",
    "href": "slides/lec-7.html#standard-errors",
    "title": "SLR: Model diagnostics",
    "section": "Standard errors",
    "text": "Standard errors\nStandard error of the mean outcome: \\[SE_{\\hat{\\mu}} = \\hat{\\sigma}_\\epsilon\\sqrt{\\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]\n. . .\nStandard error of an individual outcome: \\[SE_{\\hat{y}} = \\hat{\\sigma}_\\epsilon\\sqrt{1 + \\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]"
  },
  {
    "objectID": "slides/lec-7.html#standard-errors-1",
    "href": "slides/lec-7.html#standard-errors-1",
    "title": "SLR: Model diagnostics",
    "section": "Standard errors",
    "text": "Standard errors\nStandard error of the mean outcome: \\[SE_{\\hat{\\mu}} = \\hat{\\sigma}_\\epsilon\\sqrt{\\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]\nStandard error of an individual outcome: \\[SE_{\\hat{y}} = \\hat{\\sigma}_\\epsilon\\sqrt{\\mathbf{\\color{purple}{\\Large{1}}} + \\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]"
  },
  {
    "objectID": "slides/lec-7.html#confidence-interval",
    "href": "slides/lec-7.html#confidence-interval",
    "title": "SLR: Model diagnostics",
    "section": "Confidence interval",
    "text": "Confidence interval\nThe 95% confidence interval for the mean outcpme:\n\nnew_house &lt;- tibble(area = 2800)\n\npredict(df_fit, new_data = new_house, type = \"conf_int\", level = 0.95)\n\n# A tibble: 1 √ó 2\n  .pred_lower .pred_upper\n        &lt;dbl&gt;       &lt;dbl&gt;\n1     529351.     597060.\n\n\n. . .\nWe are 95% confident that mean sale price of Duke Forest houses that are 2,800 square feet is between $529,351 and $597,060."
  },
  {
    "objectID": "slides/lec-7.html#prediction-interval",
    "href": "slides/lec-7.html#prediction-interval",
    "title": "SLR: Model diagnostics",
    "section": "Prediction interval",
    "text": "Prediction interval\nThe 95% prediction intervalfor the individual outcome:\n\npredict(df_fit, new_data = new_house, type = \"pred_int\", level = 0.95)\n\n# A tibble: 1 √ó 2\n  .pred_lower .pred_upper\n        &lt;dbl&gt;       &lt;dbl&gt;\n1     226438.     899973.\n\n\n. . .\nWe are 95% confident that predicted sale price of a Duke Forest house that is 2,800 square feet is between $226,438 and $899,973."
  },
  {
    "objectID": "slides/lec-7.html#comparing-intervals",
    "href": "slides/lec-7.html#comparing-intervals",
    "title": "SLR: Model diagnostics",
    "section": "Comparing intervals",
    "text": "Comparing intervals"
  },
  {
    "objectID": "slides/lec-7.html#extrapolation",
    "href": "slides/lec-7.html#extrapolation",
    "title": "SLR: Model diagnostics",
    "section": "Extrapolation",
    "text": "Extrapolation\n\n\n\nCalculate the prediction interval for the sale price of a ‚Äútiny house‚Äù in Duke Forest that is 225 square feet.\n\n\n\n\n\n\n\n\n\n. . .\nNo, thanks!"
  },
  {
    "objectID": "slides/lec-7.html#model-conditions-1",
    "href": "slides/lec-7.html#model-conditions-1",
    "title": "SLR: Model diagnostics",
    "section": "Model conditions",
    "text": "Model conditions\n\nLinearity: There is a linear relationship between the outcome and predictor variables\nConstant variance: The variability of the errors is equal for all values of the predictor variable, i.e.¬†the errors are homeoscedastic\nNormality: The errors follow a normal distribution\nIndependence: The errors are independent from each other"
  },
  {
    "objectID": "slides/lec-7.html#linearity",
    "href": "slides/lec-7.html#linearity",
    "title": "SLR: Model diagnostics",
    "section": "Linearity",
    "text": "Linearity\n‚úÖ The residuals vs.¬†fitted values plot should not show a random scatter of residuals (no distinguishable pattern or structure)"
  },
  {
    "objectID": "slides/lec-7.html#residuals-vs.-fitted-values",
    "href": "slides/lec-7.html#residuals-vs.-fitted-values",
    "title": "SLR: Model diagnostics",
    "section": "Residuals vs.¬†fitted values",
    "text": "Residuals vs.¬†fitted values\n\ndf_aug &lt;- augment(df_fit$fit)\n\nggplot(df_aug, aes(x = .fitted, y = .resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  ylim(-1000000, 1000000) +\n  labs(\n    x = \"Fitted value\", y = \"Residual\",\n    title = \"Residuals vs. fitted values\"\n  )"
  },
  {
    "objectID": "slides/lec-7.html#application-exercise",
    "href": "slides/lec-7.html#application-exercise",
    "title": "SLR: Model diagnostics",
    "section": "Application exercise",
    "text": "Application exercise\n\nüìã github.com/sta210-s22/ae-3-duke-forest\n\n\n\n\n05:00"
  },
  {
    "objectID": "slides/lec-7.html#non-linear-relationships",
    "href": "slides/lec-7.html#non-linear-relationships",
    "title": "SLR: Model diagnostics",
    "section": "Non-linear relationships",
    "text": "Non-linear relationships"
  },
  {
    "objectID": "slides/lec-7.html#constant-variance",
    "href": "slides/lec-7.html#constant-variance",
    "title": "SLR: Model diagnostics",
    "section": "Constant variance",
    "text": "Constant variance\n‚úÖ The vertical spread of the residuals should be relatively constant across the plot"
  },
  {
    "objectID": "slides/lec-7.html#non-constant-variance",
    "href": "slides/lec-7.html#non-constant-variance",
    "title": "SLR: Model diagnostics",
    "section": "Non-constant variance",
    "text": "Non-constant variance"
  },
  {
    "objectID": "slides/lec-7.html#normality",
    "href": "slides/lec-7.html#normality",
    "title": "SLR: Model diagnostics",
    "section": "Normality",
    "text": "Normality"
  },
  {
    "objectID": "slides/lec-7.html#independence",
    "href": "slides/lec-7.html#independence",
    "title": "SLR: Model diagnostics",
    "section": "Independence",
    "text": "Independence\n\nWe can often check the independence assumption based on the context of the data and how the observations were collected\nIf the data were collected in a particular order, examine a scatterplot of the residuals versus order in which the data were collected\n\n. . .\n‚úÖ If this is a random sample of Duke Houses, the error for one house does not tell us anything about the error for another use"
  },
  {
    "objectID": "slides/lec-7.html#recap",
    "href": "slides/lec-7.html#recap",
    "title": "SLR: Model diagnostics",
    "section": "Recap",
    "text": "Recap\nUsed residual plots to check conditions for SLR:\n\n\n\n\nLinearity\nConstant variance\n\n\n\n\n\nNormality\nIndependence\n\n\n\n\n. . .\n\nWhich of these conditions are required for fitting a SLR? Which for simulation-based inference for the slope for an SLR? Which for inference with mathematical models?\n\n\n\n\n03:00"
  },
  {
    "objectID": "slides/lec-5.html",
    "href": "slides/lec-5.html",
    "title": "SLR: Simulation based-inference",
    "section": "",
    "text": "HW 1 posted tomorrow, due next Friday\n\n\n\n\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(usdata)      # for the county_2019 dataset\nlibrary(openintro)   # for the duke_forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\nlibrary(knitr)       # for pretty tables\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))"
  },
  {
    "objectID": "slides/lec-5.html#announcements",
    "href": "slides/lec-5.html#announcements",
    "title": "SLR: Simulation based-inference",
    "section": "",
    "text": "HW 1 posted tomorrow, due next Friday"
  },
  {
    "objectID": "slides/lec-5.html#computational-setup",
    "href": "slides/lec-5.html#computational-setup",
    "title": "SLR: Simulation based-inference",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(usdata)      # for the county_2019 dataset\nlibrary(openintro)   # for the duke_forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\nlibrary(knitr)       # for pretty tables\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))"
  },
  {
    "objectID": "slides/lec-5.html#terminology",
    "href": "slides/lec-5.html#terminology",
    "title": "SLR: Simulation based-inference",
    "section": "Terminology",
    "text": "Terminology\n\nOutcome: y\nPredictor: x\nObserved y, \\(y\\): truth\nPredicted y, \\(\\hat{y}\\): fitted, estimated\nResidual: difference between observed and predicted outcome for a given value of predictor"
  },
  {
    "objectID": "slides/lec-5.html#model-evaluation",
    "href": "slides/lec-5.html#model-evaluation",
    "title": "SLR: Simulation based-inference",
    "section": "Model evaluation",
    "text": "Model evaluation\n\nOne concern in evaluating models is how well they do for prediction\nWe‚Äôre generally interested in how well a model might do for predicting the outcome for a new observation, not for predicting the outcome for an observation we used to fit the model (and already know its observed value)\nEvaluating predictive performance: Split the data into testing and training sets, build models using only the training set, and evaluate their performance on the testing set, and repeat many times to see how your model holds up to ‚Äúnew‚Äù data\nQuantifying variability of of estimates: Bootstrap the data, fit a model, obtain coefficient estimates and/or measures of strength of fit, and repeat many times to see how your model holds up to ‚Äúnew‚Äù data\nToday we introduced these concepts, throughout the semester we‚Äôll learn how to implement them (i.e., write the code) and how to interpret their results"
  },
  {
    "objectID": "slides/lec-5.html#uninsurance-vs.-hs-graduation-in-nc",
    "href": "slides/lec-5.html#uninsurance-vs.-hs-graduation-in-nc",
    "title": "SLR: Simulation based-inference",
    "section": "Uninsurance vs.¬†HS graduation in NC",
    "text": "Uninsurance vs.¬†HS graduation in NC"
  },
  {
    "objectID": "slides/lec-5.html#uninsurance-vs.-hs-graduation-in-ny",
    "href": "slides/lec-5.html#uninsurance-vs.-hs-graduation-in-ny",
    "title": "SLR: Simulation based-inference",
    "section": "Uninsurance vs.¬†HS graduation in NY",
    "text": "Uninsurance vs.¬†HS graduation in NY\n\n\nCode\ncounty_2019_ny &lt;- county_2019 %&gt;%\n  as_tibble() %&gt;%\n  filter(state == \"New York\") %&gt;%\n  select(name, hs_grad, uninsured)\n\nggplot(county_2019_ny,\n       aes(x = hs_grad, y = uninsured)) +\n  geom_point() +\n  scale_x_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  scale_y_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  labs(\n    x = \"High school graduate\", y = \"Uninsured\",\n    title = \"Uninsurance vs. HS graduation rates\",\n    subtitle = \"New York counties, 2015 - 2019\"\n  ) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"pink\")"
  },
  {
    "objectID": "slides/lec-5.html#data-splitting",
    "href": "slides/lec-5.html#data-splitting",
    "title": "SLR: Simulation based-inference",
    "section": "Data splitting",
    "text": "Data splitting"
  },
  {
    "objectID": "slides/lec-5.html#bootstrapping",
    "href": "slides/lec-5.html#bootstrapping",
    "title": "SLR: Simulation based-inference",
    "section": "Bootstrapping",
    "text": "Bootstrapping"
  },
  {
    "objectID": "slides/lec-5.html#comparing-ny-and-nc",
    "href": "slides/lec-5.html#comparing-ny-and-nc",
    "title": "SLR: Simulation based-inference",
    "section": "Comparing NY and NC",
    "text": "Comparing NY and NC\n\nWhy are the fits from the NY models more variable than those from the NC models?"
  },
  {
    "objectID": "slides/lec-5.html#data-sale-prices-of-houses-in-duke-forest",
    "href": "slides/lec-5.html#data-sale-prices-of-houses-in-duke-forest",
    "title": "SLR: Simulation based-inference",
    "section": "Data: Sale prices of houses in Duke Forest",
    "text": "Data: Sale prices of houses in Duke Forest\n\n\n\nData on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020\nScraped from Zillow\nSource: openintro::duke_forest"
  },
  {
    "objectID": "slides/lec-5.html#exploratory-analysis",
    "href": "slides/lec-5.html#exploratory-analysis",
    "title": "SLR: Simulation based-inference",
    "section": "Exploratory analysis",
    "text": "Exploratory analysis"
  },
  {
    "objectID": "slides/lec-5.html#modeling",
    "href": "slides/lec-5.html#modeling",
    "title": "SLR: Simulation based-inference",
    "section": "Modeling",
    "text": "Modeling\n\ndf_fit &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) %&gt;%\n  kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n. . .\n\nIntercept: Duke Forest houses that are 0 square feet are expected to sell, on average, for $116,652.\nSlope: For each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159."
  },
  {
    "objectID": "slides/lec-5.html#sample-to-population",
    "href": "slides/lec-5.html#sample-to-population",
    "title": "SLR: Simulation based-inference",
    "section": "Sample to population",
    "text": "Sample to population\n\nFor each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159.\n\n\nThis estimate is valid for the single sample of 98 houses.\nBut what if we‚Äôre not interested quantifying the relationship between the size and price of a house in this single sample?\nWhat if we want to say something about the relationship between these variables for all houses in Duke Forest?"
  },
  {
    "objectID": "slides/lec-5.html#statistical-inference-1",
    "href": "slides/lec-5.html#statistical-inference-1",
    "title": "SLR: Simulation based-inference",
    "section": "Statistical inference",
    "text": "Statistical inference\n\nStatistical inference allows provide methods and tools for us to use the single sample we have observed to make valid statements (inferences) about the population it comes from\nFor our inferences to be valid, the sample should be random and representative of the population we‚Äôre interested in"
  },
  {
    "objectID": "slides/lec-5.html#inference-for-simple-linear-regression",
    "href": "slides/lec-5.html#inference-for-simple-linear-regression",
    "title": "SLR: Simulation based-inference",
    "section": "Inference for simple linear regression",
    "text": "Inference for simple linear regression\n\nCalculate a confidence interval for the slope, \\(\\beta_1\\)\nConduct a hypothesis test for the interval, \\(\\beta_1\\)"
  },
  {
    "objectID": "slides/lec-5.html#confidence-interval",
    "href": "slides/lec-5.html#confidence-interval",
    "title": "SLR: Simulation based-inference",
    "section": "Confidence interval",
    "text": "Confidence interval\n\nA plausible range of values for a population parameter is called a confidence interval\nUsing only a single point estimate is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net\n\nWe can throw a spear where we saw a fish but we will probably miss, if we toss a net in that area, we have a good chance of catching the fish\nSimilarly, if we report a point estimate, we probably will not hit the exact population parameter, but if we report a range of plausible values we have a good shot at capturing the parameter"
  },
  {
    "objectID": "slides/lec-5.html#confidence-interval-for-the-slope-1",
    "href": "slides/lec-5.html#confidence-interval-for-the-slope-1",
    "title": "SLR: Simulation based-inference",
    "section": "Confidence interval for the slope",
    "text": "Confidence interval for the slope\nA confidence interval will allow us to make a statement like ‚ÄúFor each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159, give or take X dollars.‚Äù\n\nShould X be $10? $100? $1000?\nIf we were to take another sample of 98 would we expect the slope calculated based on that sample to be exactly $159? Off by $10? $100? $1000?\nThe answer depends on how variable (from one sample to another sample) the sample statistic (the slope) is\nWe need a way to quantify the variability of the sample statistic"
  },
  {
    "objectID": "slides/lec-5.html#quantify-the-variability-of-the-slope",
    "href": "slides/lec-5.html#quantify-the-variability-of-the-slope",
    "title": "SLR: Simulation based-inference",
    "section": "Quantify the variability of the slope",
    "text": "Quantify the variability of the slope\nfor estimation\n\nTwo approaches:\n\nVia simulation (what we‚Äôll do today)\nVia mathematical models (what we‚Äôll do in the next class)\n\nBootstrapping to quantify the variability of the slope for the purpose of estimation:\n\nBootstrap new samples from the original sample\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the bootstrapped slopes to construct a confidence interval"
  },
  {
    "objectID": "slides/lec-5.html#bootstrap-sample-1",
    "href": "slides/lec-5.html#bootstrap-sample-1",
    "title": "SLR: Simulation based-inference",
    "section": "Bootstrap sample 1",
    "text": "Bootstrap sample 1"
  },
  {
    "objectID": "slides/lec-5.html#bootstrap-sample-2",
    "href": "slides/lec-5.html#bootstrap-sample-2",
    "title": "SLR: Simulation based-inference",
    "section": "Bootstrap sample 2",
    "text": "Bootstrap sample 2"
  },
  {
    "objectID": "slides/lec-5.html#bootstrap-sample-3",
    "href": "slides/lec-5.html#bootstrap-sample-3",
    "title": "SLR: Simulation based-inference",
    "section": "Bootstrap sample 3",
    "text": "Bootstrap sample 3"
  },
  {
    "objectID": "slides/lec-5.html#bootstrap-sample-4",
    "href": "slides/lec-5.html#bootstrap-sample-4",
    "title": "SLR: Simulation based-inference",
    "section": "Bootstrap sample 4",
    "text": "Bootstrap sample 4"
  },
  {
    "objectID": "slides/lec-5.html#bootstrap-sample-5",
    "href": "slides/lec-5.html#bootstrap-sample-5",
    "title": "SLR: Simulation based-inference",
    "section": "Bootstrap sample 5",
    "text": "Bootstrap sample 5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n. . .\nso on and so forth‚Ä¶"
  },
  {
    "objectID": "slides/lec-5.html#bootstrap-samples-1---5",
    "href": "slides/lec-5.html#bootstrap-samples-1---5",
    "title": "SLR: Simulation based-inference",
    "section": "Bootstrap samples 1 - 5",
    "text": "Bootstrap samples 1 - 5"
  },
  {
    "objectID": "slides/lec-5.html#bootstrap-samples-1---100",
    "href": "slides/lec-5.html#bootstrap-samples-1---100",
    "title": "SLR: Simulation based-inference",
    "section": "Bootstrap samples 1 - 100",
    "text": "Bootstrap samples 1 - 100"
  },
  {
    "objectID": "slides/lec-5.html#slopes-of-bootstrap-samples",
    "href": "slides/lec-5.html#slopes-of-bootstrap-samples",
    "title": "SLR: Simulation based-inference",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159, give or take ___ dollars."
  },
  {
    "objectID": "slides/lec-5.html#slopes-of-bootstrap-samples-1",
    "href": "slides/lec-5.html#slopes-of-bootstrap-samples-1",
    "title": "SLR: Simulation based-inference",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159, give or take ___ dollars."
  },
  {
    "objectID": "slides/lec-5.html#confidence-level",
    "href": "slides/lec-5.html#confidence-level",
    "title": "SLR: Simulation based-inference",
    "section": "Confidence level",
    "text": "Confidence level\n\nHow confident are you that the true slope is between $0 and $250? How about $150 and $170? How about $90 and $210?"
  },
  {
    "objectID": "slides/lec-5.html#confidence-interval-1",
    "href": "slides/lec-5.html#confidence-interval-1",
    "title": "SLR: Simulation based-inference",
    "section": "95% confidence interval",
    "text": "95% confidence interval\n\n\n\n\n\n\n\n\n\n\nA 95% confidence interval is bounded by the middle 95% of the bootstrap distribution\nWe are 95% confident that For each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $90.43 to $205.77."
  },
  {
    "objectID": "slides/lec-5.html#computing-the-ci-for-the-slope-i",
    "href": "slides/lec-5.html#computing-the-ci-for-the-slope-i",
    "title": "SLR: Simulation based-inference",
    "section": "Computing the CI for the slope I",
    "text": "Computing the CI for the slope I\nCalculate the observed slope:\n\nobserved_fit &lt;- duke_forest %&gt;%\n  specify(price ~ area) %&gt;%\n  fit()\n\nobserved_fit\n\n# A tibble: 2 √ó 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159."
  },
  {
    "objectID": "slides/lec-5.html#computing-the-ci-for-the-slope-ii",
    "href": "slides/lec-5.html#computing-the-ci-for-the-slope-ii",
    "title": "SLR: Simulation based-inference",
    "section": "Computing the CI for the slope II",
    "text": "Computing the CI for the slope II\nTake 100 bootstrap samples and fit models to each one:\n\n# #| code-line-numbers: \"1,5,6\"\n\nset.seed(1120)\n\nboot_fits &lt;- duke_forest %&gt;%\n  specify(price ~ area) %&gt;%\n  generate(reps = 100, type = \"bootstrap\") %&gt;%\n  fit()\n\nboot_fits\n\n# A tibble: 200 √ó 3\n# Groups:   replicate [100]\n   replicate term      estimate\n       &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1         1 intercept   47819.\n 2         1 area          191.\n 3         2 intercept  144645.\n 4         2 area          134.\n 5         3 intercept  114008.\n 6         3 area          161.\n 7         4 intercept  100639.\n 8         4 area          166.\n 9         5 intercept  215264.\n10         5 area          125.\n# ‚Ä¶ with 190 more rows"
  },
  {
    "objectID": "slides/lec-5.html#computing-the-ci-for-the-slope-iii",
    "href": "slides/lec-5.html#computing-the-ci-for-the-slope-iii",
    "title": "SLR: Simulation based-inference",
    "section": "Computing the CI for the slope III",
    "text": "Computing the CI for the slope III\nPercentile method: Compute the 95% CI as the middle 95% of the bootstrap distribution:\n\n# #| code-line-numbers: \"5\"\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\"\n)\n\n# A tibble: 2 √ó 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/lec-5.html#computing-the-ci-for-the-slope-iv",
    "href": "slides/lec-5.html#computing-the-ci-for-the-slope-iv",
    "title": "SLR: Simulation based-inference",
    "section": "Computing the CI for the slope IV",
    "text": "Computing the CI for the slope IV\nStandard error method: Alternatively, compute the 95% CI as the point estimate \\(\\pm\\) ~2 standard deviations of the bootstrap distribution:\n\n# #| code-line-numbers: \"5\"\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"se\"\n)\n\n# A tibble: 2 √ó 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          90.8     228.\n2 intercept -56788.   290093."
  },
  {
    "objectID": "slides/lec-5.html#precision-vs.-accuracy",
    "href": "slides/lec-5.html#precision-vs.-accuracy",
    "title": "SLR: Simulation based-inference",
    "section": "Precision vs.¬†accuracy",
    "text": "Precision vs.¬†accuracy\n\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?\n\n. . ."
  },
  {
    "objectID": "slides/lec-5.html#precision-vs.-accuracy-1",
    "href": "slides/lec-5.html#precision-vs.-accuracy-1",
    "title": "SLR: Simulation based-inference",
    "section": "Precision vs.¬†accuracy",
    "text": "Precision vs.¬†accuracy\n\nHow can we get best of both worlds ‚Äì high precision and high accuracy?"
  },
  {
    "objectID": "slides/lec-5.html#changing-confidence-level",
    "href": "slides/lec-5.html#changing-confidence-level",
    "title": "SLR: Simulation based-inference",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\nHow would you modify the following code to calculate a 90% confidence interval? How would you modify it for a 99% confidence interval?\n\n\n# #| code-line-numbers: \"|4\"\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\"\n)\n\n# A tibble: 2 √ó 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/lec-5.html#changing-confidence-level-1",
    "href": "slides/lec-5.html#changing-confidence-level-1",
    "title": "SLR: Simulation based-inference",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\n## confidence level: 90%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.90, type = \"percentile\"\n)\n\n# A tibble: 2 √ó 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          104.     212.\n2 intercept  -24380.  256730.\n\n## confidence level: 99%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.99, type = \"percentile\"\n)\n\n# A tibble: 2 √ó 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          56.3     226.\n2 intercept -61950.   370395."
  },
  {
    "objectID": "slides/lec-5.html#recap",
    "href": "slides/lec-5.html#recap",
    "title": "SLR: Simulation based-inference",
    "section": "Recap",
    "text": "Recap\n\nPopulation: Complete set of observations of whatever we are studying, e.g., people, tweets, photographs, etc. (population size = \\(N\\))\nSample: Subset of the population, ideally random and representative (sample size = \\(n\\))\nSample statistic \\(\\ne\\) population parameter, but if the sample is good, it can be a good estimate\nStatistical inference: Discipline that concerns itself with the development of procedures, methods, and theorems that allow us to extract meaning and information from data that has been generated by stochastic (random) process\nWe report the estimate with a confidence interval, and the width of this interval depends on the variability of sample statistics from different samples from the population\nSince we can‚Äôt continue sampling from the population, we bootstrap from the one sample we have to estimate sampling variability"
  },
  {
    "objectID": "slides/lec-5.html#sampling-is-natural",
    "href": "slides/lec-5.html#sampling-is-natural",
    "title": "SLR: Simulation based-inference",
    "section": "Sampling is natural",
    "text": "Sampling is natural\n\n\n\n\n\n\nWhen you taste a spoonful of soup and decide the spoonful you tasted isn‚Äôt salty enough, that‚Äôs exploratory analysis\nIf you generalize and conclude that your entire soup needs salt, that‚Äôs an inference\nFor your inference to be valid, the spoonful you tasted (the sample) needs to be representative of the entire pot (the population)"
  },
  {
    "objectID": "slides/lec-5.html#statistical-significance",
    "href": "slides/lec-5.html#statistical-significance",
    "title": "SLR: Simulation based-inference",
    "section": "Statistical significance",
    "text": "Statistical significance\n\n\nDo the data provide sufficient evidence that \\(\\beta_1\\) (the true slope for the population) is different from 0?"
  },
  {
    "objectID": "slides/lec-5.html#hypotheses",
    "href": "slides/lec-5.html#hypotheses",
    "title": "SLR: Simulation based-inference",
    "section": "Hypotheses",
    "text": "Hypotheses\n\nWe want to answer the question ‚ÄúDo the data provide sufficient evidence that \\(\\beta_1\\) (the true slope for the population) is different from 0?‚Äù\nNull hypothesis - \\(H_0: \\beta_1 = 0\\), there is no linear relationship between area and price\nAlternative hypothesis - \\(H_A: \\beta_1 \\ne 0\\), there is a linear relationship between area and price"
  },
  {
    "objectID": "slides/lec-5.html#hypothesis-testing-as-a-court-trial",
    "href": "slides/lec-5.html#hypothesis-testing-as-a-court-trial",
    "title": "SLR: Simulation based-inference",
    "section": "Hypothesis testing as a court trial",
    "text": "Hypothesis testing as a court trial\n\nNull hypothesis, \\(H_0\\): Defendant is innocent\nAlternative hypothesis, \\(H_A\\): Defendant is guilty\nPresent the evidence: Collect data\nJudge the evidence: ‚ÄúCould these data plausibly have happened by chance if the null hypothesis were true?‚Äù\n\nYes: Fail to reject \\(H_0\\)\nNo: Reject \\(H_0\\)"
  },
  {
    "objectID": "slides/lec-5.html#hypothesis-testing-framework",
    "href": "slides/lec-5.html#hypothesis-testing-framework",
    "title": "SLR: Simulation based-inference",
    "section": "Hypothesis testing framework",
    "text": "Hypothesis testing framework\n\nStart with a null hypothesis, \\(H_0\\) that represents the status quo\nSet an alternative hypothesis, \\(H_A\\) that represents the research question, i.e.¬†what we‚Äôre testing for\nConduct a hypothesis test under the assumption that the null hypothesis is true and calculate a p-value (probability of observed or more extreme outcome given that the null hypothesis is true)\n\nif the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, stick with the null hypothesis\nif they do, then reject the null hypothesis in favor of the alternative"
  },
  {
    "objectID": "slides/lec-3.html",
    "href": "slides/lec-3.html",
    "title": "SLR: Model fitting in R with tidymodels",
    "section": "",
    "text": "If you‚Äôre just joining the class, welcome! Go to the course website and review content you‚Äôve missed, read the syllabus, and complete the Getting to know you survey.\nLab 1 is due Friday, at 5pm, on Gradescope.\n\n\n\n\n\n\nUsed simple linear regression to describe the relationship between a quantitative predictor and quantitative outcome variable.\nUsed the least squares method to estimate the slope and intercept.\nWe interpreted the slope and intercept.\n\n\nSlope: For every one unit increase in \\(x\\), we expect y to be higher/lower by \\(\\hat{\\beta}_1\\) units, on average.\nIntercept: If \\(x\\) is 0, then we expect \\(y\\) to be \\(\\hat{\\beta}_0\\) units.\n\n\nPredicted the response given a value of the predictor variable.\nDefined extrapolation and why we should avoid it.\n\n\n\n\n\nSee the supplemental notes on Deriving the Least-Squares Estimates for Simple Linear Regression for more mathematical details on the derivations of the estimates of \\(\\beta_0\\) and \\(\\beta_1\\).\n\n\n\n\nUse tidymodels to fit and summarize regression models in R\nComplete an application exercise on exploratory data analysis and modeling\n\n\n\n\n\n# load packages\nlibrary(tidyverse)       # for data wrangling\n\nWarning: package 'tidyverse' was built under R version 4.1.2\n\n\nWarning: package 'tibble' was built under R version 4.1.3\n\n\nWarning: package 'tidyr' was built under R version 4.1.3\n\n\nWarning: package 'readr' was built under R version 4.1.2\n\n\nWarning: package 'dplyr' was built under R version 4.1.3\n\n\nWarning: package 'stringr' was built under R version 4.1.3\n\n\nWarning: package 'forcats' was built under R version 4.1.2\n\nlibrary(tidymodels)      # for modeling\n\nWarning: package 'dials' was built under R version 4.1.3\n\n\nWarning: package 'scales' was built under R version 4.1.3\n\n\nWarning: package 'workflows' was built under R version 4.1.3\n\n\nWarning: package 'workflowsets' was built under R version 4.1.3\n\nlibrary(fivethirtyeight) # for the fandango dataset\n\nWarning: package 'fivethirtyeight' was built under R version 4.1.3\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))\n\n# set default figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 8,\n  fig.asp = 0.618,\n  fig.retina = 3,\n  dpi = 300,\n  out.width = \"80%\"\n)"
  },
  {
    "objectID": "slides/lec-3.html#announcements",
    "href": "slides/lec-3.html#announcements",
    "title": "SLR: Model fitting in R with tidymodels",
    "section": "",
    "text": "If you‚Äôre just joining the class, welcome! Go to the course website and review content you‚Äôve missed, read the syllabus, and complete the Getting to know you survey.\nLab 1 is due Friday, at 5pm, on Gradescope."
  },
  {
    "objectID": "slides/lec-3.html#recap-of-last-lecture",
    "href": "slides/lec-3.html#recap-of-last-lecture",
    "title": "SLR: Model fitting in R with tidymodels",
    "section": "",
    "text": "Used simple linear regression to describe the relationship between a quantitative predictor and quantitative outcome variable.\nUsed the least squares method to estimate the slope and intercept.\nWe interpreted the slope and intercept.\n\n\nSlope: For every one unit increase in \\(x\\), we expect y to be higher/lower by \\(\\hat{\\beta}_1\\) units, on average.\nIntercept: If \\(x\\) is 0, then we expect \\(y\\) to be \\(\\hat{\\beta}_0\\) units.\n\n\nPredicted the response given a value of the predictor variable.\nDefined extrapolation and why we should avoid it."
  },
  {
    "objectID": "slides/lec-3.html#interested-in-the-math-behind-it-all",
    "href": "slides/lec-3.html#interested-in-the-math-behind-it-all",
    "title": "SLR: Model fitting in R with tidymodels",
    "section": "",
    "text": "See the supplemental notes on Deriving the Least-Squares Estimates for Simple Linear Regression for more mathematical details on the derivations of the estimates of \\(\\beta_0\\) and \\(\\beta_1\\)."
  },
  {
    "objectID": "slides/lec-3.html#outline",
    "href": "slides/lec-3.html#outline",
    "title": "SLR: Model fitting in R with tidymodels",
    "section": "",
    "text": "Use tidymodels to fit and summarize regression models in R\nComplete an application exercise on exploratory data analysis and modeling"
  },
  {
    "objectID": "slides/lec-3.html#computational-setup",
    "href": "slides/lec-3.html#computational-setup",
    "title": "SLR: Model fitting in R with tidymodels",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)       # for data wrangling\n\nWarning: package 'tidyverse' was built under R version 4.1.2\n\n\nWarning: package 'tibble' was built under R version 4.1.3\n\n\nWarning: package 'tidyr' was built under R version 4.1.3\n\n\nWarning: package 'readr' was built under R version 4.1.2\n\n\nWarning: package 'dplyr' was built under R version 4.1.3\n\n\nWarning: package 'stringr' was built under R version 4.1.3\n\n\nWarning: package 'forcats' was built under R version 4.1.2\n\nlibrary(tidymodels)      # for modeling\n\nWarning: package 'dials' was built under R version 4.1.3\n\n\nWarning: package 'scales' was built under R version 4.1.3\n\n\nWarning: package 'workflows' was built under R version 4.1.3\n\n\nWarning: package 'workflowsets' was built under R version 4.1.3\n\nlibrary(fivethirtyeight) # for the fandango dataset\n\nWarning: package 'fivethirtyeight' was built under R version 4.1.3\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))\n\n# set default figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 8,\n  fig.asp = 0.618,\n  fig.retina = 3,\n  dpi = 300,\n  out.width = \"80%\"\n)"
  },
  {
    "objectID": "slides/lec-3.html#movie-ratings",
    "href": "slides/lec-3.html#movie-ratings",
    "title": "SLR: Model fitting in R with tidymodels",
    "section": "Movie ratings",
    "text": "Movie ratings\n\n\n\nData behind the FiveThirtyEight story\nIn the fivethirtyeight package: fandango\nContains every film that has at least 30 fan reviews on Fandango, an IMDb score, Rotten Tomatoes critic and user ratings, and Metacritic critic and user scores"
  },
  {
    "objectID": "slides/lec-3.html#data-prep",
    "href": "slides/lec-3.html#data-prep",
    "title": "SLR: Model fitting in R with tidymodels",
    "section": "Data prep",
    "text": "Data prep\n\nRename Rotten Tomatoes columns as critics and audience\nRename the dataset as movie_scores\n\n\nmovie_scores &lt;- fandango %&gt;%\n  rename(\n    critics = rottentomatoes, \n    audience = rottentomatoes_user\n  )"
  },
  {
    "objectID": "slides/lec-3.html#data-visualization",
    "href": "slides/lec-3.html#data-visualization",
    "title": "SLR: Model fitting in R with tidymodels",
    "section": "Data visualization",
    "text": "Data visualization\n\nggplot(movie_scores, \n       aes(x = critics, y = audience)) +\n  geom_point(alpha = 0.5) + \n  labs(\n    x = \"Critics Score\" , \n    y = \"Audience Score\"\n    )"
  },
  {
    "objectID": "slides/lec-3.html#step-1-specify-model",
    "href": "slides/lec-3.html#step-1-specify-model",
    "title": "SLR: Model fitting in R with tidymodels",
    "section": "Step 1: Specify model",
    "text": "Step 1: Specify model\n\nlinear_reg()\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm"
  },
  {
    "objectID": "slides/lec-3.html#step-2-set-model-fitting-engine",
    "href": "slides/lec-3.html#step-2-set-model-fitting-engine",
    "title": "SLR: Model fitting in R with tidymodels",
    "section": "Step 2: Set model fitting engine",
    "text": "Step 2: Set model fitting engine\n\n# #| code-line-numbers: \"|2\"\n\nlinear_reg() %&gt;%\n  set_engine(\"lm\") # lm: linear model\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm"
  },
  {
    "objectID": "slides/lec-3.html#step-3-fit-model-estimate-parameters",
    "href": "slides/lec-3.html#step-3-fit-model-estimate-parameters",
    "title": "SLR: Model fitting in R with tidymodels",
    "section": "Step 3: Fit model & estimate parameters",
    "text": "Step 3: Fit model & estimate parameters\nusing formula syntax\n\n# #| code-line-numbers: \"|3\"\n\nlinear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  fit(audience ~ critics, data = movie_scores)\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = audience ~ critics, data = data)\n\nCoefficients:\n(Intercept)      critics  \n    32.3155       0.5187"
  },
  {
    "objectID": "slides/lec-3.html#a-closer-look-at-model-output",
    "href": "slides/lec-3.html#a-closer-look-at-model-output",
    "title": "SLR: Model fitting in R with tidymodels",
    "section": "A closer look at model output",
    "text": "A closer look at model output\n\nmovie_fit &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  fit(audience ~ critics, data = movie_scores)\n\nmovie_fit\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = audience ~ critics, data = data)\n\nCoefficients:\n(Intercept)      critics  \n    32.3155       0.5187  \n\n\n\\[\\widehat{\\text{audience}} = 32.3155 + 0.5187 \\times \\text{critics}\\]\n. . .\nNote: The intercept is off by a tiny bit from the hand-calculated intercept, this is likely just rounding error in the hand calculation."
  },
  {
    "objectID": "slides/lec-3.html#the-regression-output",
    "href": "slides/lec-3.html#the-regression-output",
    "title": "SLR: Model fitting in R with tidymodels",
    "section": "The regression output",
    "text": "The regression output\nWe‚Äôll focus on the first column for now‚Ä¶\n\n# #| code-line-numbers: \"|4\"\n\nlinear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  fit(audience ~ critics, data = movie_scores) %&gt;%\n  tidy()\n\n# A tibble: 2 x 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   32.3      2.34        13.8 4.03e-28\n2 critics        0.519    0.0345      15.0 2.70e-31"
  },
  {
    "objectID": "slides/lec-3.html#prediction",
    "href": "slides/lec-3.html#prediction",
    "title": "SLR: Model fitting in R with tidymodels",
    "section": "Prediction",
    "text": "Prediction\n\n# #| code-line-numbers: \"|2|5\"\n\n# create a data frame for a new movie\nnew_movie &lt;- tibble(critics = 50)\n\n# predict the outcome for a new movie\npredict(movie_fit, new_movie)\n\n# A tibble: 1 x 1\n  .pred\n  &lt;dbl&gt;\n1  58.2"
  },
  {
    "objectID": "slides/lec-4.html",
    "href": "slides/lec-4.html",
    "title": "SLR: Prediction + model evaluation",
    "section": "",
    "text": "New on the course website: FAQ\nNew communication tool: Slack\n\nFind the invite link in your inbox / on Sakai announcements\nUse #general for questions, #random for random ü§™\nUse code formatting for for questions involving code (see Course FAQ for a demo video)\n\nMy office hours: All virtual for now, hope to move 1 hour / week to in person later in the semester\n\n\n\n\n\nLectures:\n\nIn person as long as university says so (and I don‚Äôt have COVID)\nIf you can‚Äôt be in class (and you‚Äôre well enough to follow along), watch live (or the recording later) on Panopto\nWatching live and have questions? Post on Slack!\nIn class and see someone ask a question on Slack? Please raise it to me!\n\nLabs:\n\nNot live streamed / recorded\nLab 2 (next Monday) - individual\nLab 3 onwards - in teams, if teammates are in isolation, set up team Zoom calls\n\n\n\n\n\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(usdata)      # for the county_2019 dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))"
  },
  {
    "objectID": "slides/lec-4.html#announcements",
    "href": "slides/lec-4.html#announcements",
    "title": "SLR: Prediction + model evaluation",
    "section": "",
    "text": "New on the course website: FAQ\nNew communication tool: Slack\n\nFind the invite link in your inbox / on Sakai announcements\nUse #general for questions, #random for random ü§™\nUse code formatting for for questions involving code (see Course FAQ for a demo video)\n\nMy office hours: All virtual for now, hope to move 1 hour / week to in person later in the semester"
  },
  {
    "objectID": "slides/lec-4.html#hybrid-teaching",
    "href": "slides/lec-4.html#hybrid-teaching",
    "title": "SLR: Prediction + model evaluation",
    "section": "",
    "text": "Lectures:\n\nIn person as long as university says so (and I don‚Äôt have COVID)\nIf you can‚Äôt be in class (and you‚Äôre well enough to follow along), watch live (or the recording later) on Panopto\nWatching live and have questions? Post on Slack!\nIn class and see someone ask a question on Slack? Please raise it to me!\n\nLabs:\n\nNot live streamed / recorded\nLab 2 (next Monday) - individual\nLab 3 onwards - in teams, if teammates are in isolation, set up team Zoom calls"
  },
  {
    "objectID": "slides/lec-4.html#computational-setup",
    "href": "slides/lec-4.html#computational-setup",
    "title": "SLR: Prediction + model evaluation",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(usdata)      # for the county_2019 dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))"
  },
  {
    "objectID": "slides/lec-4.html#data-source",
    "href": "slides/lec-4.html#data-source",
    "title": "SLR: Prediction + model evaluation",
    "section": "Data source",
    "text": "Data source\n\nThe data come from usdata::county_2019\nThese data have been compiled from the 2019 American Community Survey"
  },
  {
    "objectID": "slides/lec-4.html#uninsurance-rate",
    "href": "slides/lec-4.html#uninsurance-rate",
    "title": "SLR: Prediction + model evaluation",
    "section": "Uninsurance rate",
    "text": "Uninsurance rate"
  },
  {
    "objectID": "slides/lec-4.html#high-school-graduation-rate",
    "href": "slides/lec-4.html#high-school-graduation-rate",
    "title": "SLR: Prediction + model evaluation",
    "section": "High school graduation rate",
    "text": "High school graduation rate"
  },
  {
    "objectID": "slides/lec-4.html#examining-the-relationship",
    "href": "slides/lec-4.html#examining-the-relationship",
    "title": "SLR: Prediction + model evaluation",
    "section": "Examining the relationship",
    "text": "Examining the relationship\n\nThe NC Labor and Economic Analysis Division (LEAD), which ‚Äúadministers and collects data, conducts research, and publishes information on the state‚Äôs economy, labor force, educational, and workforce-related issues‚Äù.\nSuppose that an analyst working for LEAD is interested in the relationship between uninsurance and high school graduation rates in NC counties.\n\n. . .\n\nWhat type of visualization should the analyst make to examine the relationship between these two variables?"
  },
  {
    "objectID": "slides/lec-4.html#data-prep",
    "href": "slides/lec-4.html#data-prep",
    "title": "SLR: Prediction + model evaluation",
    "section": "Data prep",
    "text": "Data prep\n\ncounty_2019_nc &lt;- county_2019 %&gt;%\n  as_tibble() %&gt;%\n  filter(state == \"North Carolina\") %&gt;%\n  select(name, hs_grad, uninsured)\n\ncounty_2019_nc\n\n# A tibble: 100 √ó 3\n   name             hs_grad uninsured\n   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;\n 1 Alamance County     86.3      11.2\n 2 Alexander County    82.4       8.9\n 3 Alleghany County    77.5      11.3\n 4 Anson County        80.7      11.1\n 5 Ashe County         85.1      12.6\n 6 Avery County        83.6      15.9\n 7 Beaufort County     87.7      12  \n 8 Bertie County       78.4      11.9\n 9 Bladen County       81.3      12.9\n10 Brunswick County    91.3       9.8\n# ‚Ä¶ with 90 more rows"
  },
  {
    "objectID": "slides/lec-4.html#uninsurance-vs.-hs-graduation-rates",
    "href": "slides/lec-4.html#uninsurance-vs.-hs-graduation-rates",
    "title": "SLR: Prediction + model evaluation",
    "section": "Uninsurance vs.¬†HS graduation rates",
    "text": "Uninsurance vs.¬†HS graduation rates\n\n\nCode\nggplot(county_2019_nc,\n       aes(x = hs_grad, y = uninsured)) +\n  geom_point() +\n  scale_x_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  scale_y_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  labs(\n    x = \"High school graduate\", y = \"Uninsured\",\n    title = \"Uninsurance vs. HS graduation rates\",\n    subtitle = \"North Carolina counties, 2015 - 2019\"\n  ) +\n  geom_point(data = county_2019_nc %&gt;% filter(name == \"Durham County\"), aes(x = hs_grad, y = uninsured), shape = \"circle open\", color = \"#8F2D56\", size = 4, stroke = 2) +\n  geom_text(data = county_2019_nc %&gt;% filter(name == \"Durham County\"), aes(x = hs_grad, y = uninsured, label = name), color = \"#8F2D56\", fontface = \"bold\", nudge_y = 3, nudge_x = 2)"
  },
  {
    "objectID": "slides/lec-4.html#modeling-the-relationship",
    "href": "slides/lec-4.html#modeling-the-relationship",
    "title": "SLR: Prediction + model evaluation",
    "section": "Modeling the relationship",
    "text": "Modeling the relationship\n\n\nCode\nggplot(county_2019_nc, aes(x = hs_grad, y = uninsured)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"#8F2D56\") +\n  scale_x_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  scale_y_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  labs(\n    x = \"High school graduate\", y = \"Uninsured\",\n    title = \"Uninsurance vs. HS graduation rates\",\n    subtitle = \"North Carolina counties, 2015 - 2019\"\n  )"
  },
  {
    "objectID": "slides/lec-4.html#fitting-the-model",
    "href": "slides/lec-4.html#fitting-the-model",
    "title": "SLR: Prediction + model evaluation",
    "section": "Fitting the model",
    "text": "Fitting the model\nWith fit():\n\nnc_fit &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  fit(uninsured ~ hs_grad, data = county_2019_nc)\n\ntidy(nc_fit)\n\n# A tibble: 2 √ó 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   33.9      3.99        8.50 2.12e-13\n2 hs_grad       -0.262    0.0468     -5.61 1.88e- 7"
  },
  {
    "objectID": "slides/lec-4.html#augmenting-the-data",
    "href": "slides/lec-4.html#augmenting-the-data",
    "title": "SLR: Prediction + model evaluation",
    "section": "Augmenting the data",
    "text": "Augmenting the data\nWith augment() to add columns for predicted values (.fitted), residuals (.resid), etc.:\n\nnc_aug &lt;- augment(nc_fit$fit)\nnc_aug\n\n# A tibble: 100 √ó 8\n   uninsured hs_grad .fitted  .resid   .hat .sigma    .cooksd .std.resid\n       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1      11.2    86.3   11.3  -0.0633 0.0107   2.10 0.00000501    -0.0305\n 2       8.9    82.4   12.3  -3.39   0.0138   2.07 0.0186        -1.63  \n 3      11.3    77.5   13.6  -2.27   0.0393   2.09 0.0252        -1.11  \n 4      11.1    80.7   12.7  -1.63   0.0199   2.09 0.00633       -0.790 \n 5      12.6    85.1   11.6   1.02   0.0100   2.10 0.00122        0.492 \n 6      15.9    83.6   12.0   3.93   0.0112   2.06 0.0203         1.89  \n 7      12      87.7   10.9   1.10   0.0133   2.10 0.00191        0.532 \n 8      11.9    78.4   13.3  -1.44   0.0328   2.09 0.00830       -0.700 \n 9      12.9    81.3   12.6   0.324  0.0174   2.10 0.000218       0.157 \n10       9.8    91.3    9.95 -0.151  0.0291   2.10 0.0000806     -0.0734\n# ‚Ä¶ with 90 more rows"
  },
  {
    "objectID": "slides/lec-4.html#visualizing-the-model-i",
    "href": "slides/lec-4.html#visualizing-the-model-i",
    "title": "SLR: Prediction + model evaluation",
    "section": "Visualizing the model I",
    "text": "Visualizing the model I\n\n\n\n\nBlack circles: Observed values (y = uninsured)"
  },
  {
    "objectID": "slides/lec-4.html#visualizing-the-model-ii",
    "href": "slides/lec-4.html#visualizing-the-model-ii",
    "title": "SLR: Prediction + model evaluation",
    "section": "Visualizing the model II",
    "text": "Visualizing the model II\n\n\n\n\nBlack circles: Observed values (y = uninsured)\nPink solid line: Least squares regression line"
  },
  {
    "objectID": "slides/lec-4.html#visualizing-the-model-iii",
    "href": "slides/lec-4.html#visualizing-the-model-iii",
    "title": "SLR: Prediction + model evaluation",
    "section": "Visualizing the model III",
    "text": "Visualizing the model III\n\n\n\n\nBlack circles: Observed values (y = uninsured)\nPink solid line: Least squares regression line\nMaroon triangles: Predicted values (y = .fitted)"
  },
  {
    "objectID": "slides/lec-4.html#visualizing-the-model-iv",
    "href": "slides/lec-4.html#visualizing-the-model-iv",
    "title": "SLR: Prediction + model evaluation",
    "section": "Visualizing the model IV",
    "text": "Visualizing the model IV\n\n\n\n\nBlack circles: Observed values (y = uninsured)\nPink solid line: Least squares regression line\nMaroon triangles: Predicted values (y = .fitted)\nGray dashed lines: Residuals"
  },
  {
    "objectID": "slides/lec-4.html#evaluating-the-model-fit",
    "href": "slides/lec-4.html#evaluating-the-model-fit",
    "title": "SLR: Prediction + model evaluation",
    "section": "Evaluating the model fit",
    "text": "Evaluating the model fit\n\nHow can we evaluate whether the model for predicting uninsurance rate from high school graduation rate for NC counties is a good fit?"
  },
  {
    "objectID": "slides/lec-4.html#two-statistics",
    "href": "slides/lec-4.html#two-statistics",
    "title": "SLR: Prediction + model evaluation",
    "section": "Two statistics",
    "text": "Two statistics\n\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model (in the context of SLR, the predictor)\n\\[\nR^2 = Cor(x,y)^2 = Cor(y, \\hat{y})^2\n\\]\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\n\\[\nRMSE = \\sqrt{\\frac{\\sum_{i = 1}^n (y_i - \\hat{y}_i)^2}{n}}\n\\]\n\n. . .\n\nWhat indicates a good model fit? Higher or lower \\(R^2\\)? Higher or lower RMSE?"
  },
  {
    "objectID": "slides/lec-4.html#r-squared",
    "href": "slides/lec-4.html#r-squared",
    "title": "SLR: Prediction + model evaluation",
    "section": "R-squared",
    "text": "R-squared\n\nRanges between 0 (terrible predictor) and 1 (perfect predictor)\nUnitless\nCalculate with rsq():\n\nrsq(nc_aug, truth = uninsured, estimate = .fitted)\n\n# A tibble: 1 √ó 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rsq     standard       0.243"
  },
  {
    "objectID": "slides/lec-4.html#interpreting-r-squared",
    "href": "slides/lec-4.html#interpreting-r-squared",
    "title": "SLR: Prediction + model evaluation",
    "section": "Interpreting R-squared",
    "text": "Interpreting R-squared\n\nüó≥Ô∏è Vote on Slack\nThe \\(R^2\\) of the model for predicting uninsurance rate from high school graduation rate for NC counties is 24.3%. Which of the following is the correct interpretation of this value?\n\n\nHigh school graduation rates correctly predict 24.3% of uninsurance rates in NC counties.\n24.3% of the variability in uninsurance rates in NC counties can be explained by high school graduation rates.\n24.3% of the variability in high school graduation rates in NC counties can be explained by uninsurance rates.\n24.3% of the time uninsurance rates in NC counties can be predicted by high school graduation rates."
  },
  {
    "objectID": "slides/lec-4.html#alternative-approach-for-r-squared",
    "href": "slides/lec-4.html#alternative-approach-for-r-squared",
    "title": "SLR: Prediction + model evaluation",
    "section": "Alternative approach for R-squared",
    "text": "Alternative approach for R-squared\nAlternatively, use glance() to construct a single row summary of the model fit, including \\(R^2\\):\n\nglance(nc_fit)\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic     p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.243         0.235  2.09      31.5 0.000000188     1  -214.  435.  443.\n# ‚Ä¶ with 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\nglance(nc_fit)$r.squared\n\n[1] 0.2430694"
  },
  {
    "objectID": "slides/lec-4.html#rmse",
    "href": "slides/lec-4.html#rmse",
    "title": "SLR: Prediction + model evaluation",
    "section": "RMSE",
    "text": "RMSE\n\nRanges between 0 (perfect predictor) and infinity (terrible predictor)\nSame units as the outcome variable\nCalculate with rmse():\n\nrmse(nc_aug, truth = uninsured, estimate = .fitted)\n\n# A tibble: 1 √ó 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard        2.07\n\n\nThe value of RMSE is not very meaningful on its own, but it‚Äôs useful for comparing across models (more on this when we get to regression with multiple predictors)"
  },
  {
    "objectID": "slides/lec-4.html#obtaining-r-squared-and-rmse",
    "href": "slides/lec-4.html#obtaining-r-squared-and-rmse",
    "title": "SLR: Prediction + model evaluation",
    "section": "Obtaining R-squared and RMSE",
    "text": "Obtaining R-squared and RMSE\n\nUse rsq() and rmse(), respectively\n\nrsq(nc_aug, truth = uninsured, estimate = .fitted)\nrmse(nc_aug, truth = uninsured, estimate = .fitted)\n\nFirst argument: data frame containing truth and estimate columns\nSecond argument: name of the column containing truth (observed outcome)\nThird argument: name of the column containing estimate (predicted outcome)"
  },
  {
    "objectID": "slides/lec-4.html#purpose-of-model-evaluation",
    "href": "slides/lec-4.html#purpose-of-model-evaluation",
    "title": "SLR: Prediction + model evaluation",
    "section": "Purpose of model evaluation",
    "text": "Purpose of model evaluation\n\n\\(R^2\\) tells us how our model is doing to predict the data we already have\nBut generally we are interested in prediction for a new observation, not for one that is already in our sample, i.e.¬†out-of-sample prediction\nWe have a couple ways of simulating out-of-sample prediction before actually getting new data to evaluate the performance of our models"
  },
  {
    "objectID": "slides/lec-4.html#spending-our-data",
    "href": "slides/lec-4.html#spending-our-data",
    "title": "SLR: Prediction + model evaluation",
    "section": "Spending our data",
    "text": "Spending our data\n\nThere are several steps to create a useful model: parameter estimation, model selection, performance assessment, etc.\nDoing all of this on the entire data we have available leaves us with no other data to assess our choices\nWe can allocate specific subsets of data for different tasks, as opposed to allocating the largest possible amount to the model parameter estimation only (which is what we‚Äôve done so far)"
  },
  {
    "objectID": "slides/lec-4.html#simulation-data-splitting",
    "href": "slides/lec-4.html#simulation-data-splitting",
    "title": "SLR: Prediction + model evaluation",
    "section": "Simulation: data splitting",
    "text": "Simulation: data splitting\n\n\n\n\nTake a random sample of 10% of the data and set aside (testing data)\nFit a model on the remaining 90% of the data (training data)\nUse the coefficients from this model to make predictions for the testing data\nRepeat 10 times"
  },
  {
    "objectID": "slides/lec-4.html#predictive-performance",
    "href": "slides/lec-4.html#predictive-performance",
    "title": "SLR: Prediction + model evaluation",
    "section": "Predictive performance",
    "text": "Predictive performance\n\n\n\n\n\nHow consistent are the predictions for different testing datasets?\nHow consistent are the predictions for counties with high school graduation rates in the middle of the plot vs.¬†in the edges?"
  },
  {
    "objectID": "slides/lec-4.html#bootstrapping-our-data",
    "href": "slides/lec-4.html#bootstrapping-our-data",
    "title": "SLR: Prediction + model evaluation",
    "section": "Bootstrapping our data",
    "text": "Bootstrapping our data\n\nThe idea behind bootstrapping is that if a given observation exists in a sample, there may be more like it in the population\nWith bootstrapping, we simulate resampling from the population by resampling from the sample we observed\nBootstrap samples are the sampled with replacement from the original sample and same size as the original sample\n\nFor example, if our sample consists of the observations {A, B, C}, bootstrap samples could be {A, A, B}, {A, C, A}, {B, C, C}, {A, B, C}, etc."
  },
  {
    "objectID": "slides/lec-4.html#simulation-bootstrapping",
    "href": "slides/lec-4.html#simulation-bootstrapping",
    "title": "SLR: Prediction + model evaluation",
    "section": "Simulation: bootstrapping",
    "text": "Simulation: bootstrapping\n\n\n\n\nTake a bootstrap sample ‚Äì sample with replacement from the original data, same size as the original data\nFit model to the sample and make predictions for that sample\nRepeat many times"
  },
  {
    "objectID": "slides/lec-4.html#predictive-performance-1",
    "href": "slides/lec-4.html#predictive-performance-1",
    "title": "SLR: Prediction + model evaluation",
    "section": "Predictive performance",
    "text": "Predictive performance\n\n\n\n\n\nHow consistent are the predictions for different bootstrap datasets?\nHow consistent are the predictions for counties with high school graduation rates in the middle of the plot vs.¬†in the edges?"
  },
  {
    "objectID": "slides/lec-6.html",
    "href": "slides/lec-6.html",
    "title": "SLR: Mathematical models for inference",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(openintro)   # for the duke_forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(knitr)       # for pretty tables\nlibrary(kableExtra)  # also for pretty tables\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 20))"
  },
  {
    "objectID": "slides/lec-6.html#computational-setup",
    "href": "slides/lec-6.html#computational-setup",
    "title": "SLR: Mathematical models for inference",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(openintro)   # for the duke_forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(knitr)       # for pretty tables\nlibrary(kableExtra)  # also for pretty tables\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 20))"
  },
  {
    "objectID": "slides/lec-6.html#data-duke-forest-houses",
    "href": "slides/lec-6.html#data-duke-forest-houses",
    "title": "SLR: Mathematical models for inference",
    "section": "Data: Duke Forest houses",
    "text": "Data: Duke Forest houses"
  },
  {
    "objectID": "slides/lec-6.html#the-regression-model",
    "href": "slides/lec-6.html#the-regression-model",
    "title": "SLR: Mathematical models for inference",
    "section": "The regression model",
    "text": "The regression model\n\ndf_fit &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) %&gt;%\n  kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\n. . .\n\nIntercept: Duke Forest houses that are 0 square feet are expected to sell, on average, for $116,652.\nSlope: For each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159."
  },
  {
    "objectID": "slides/lec-6.html#inference-for-simple-linear-regression",
    "href": "slides/lec-6.html#inference-for-simple-linear-regression",
    "title": "SLR: Mathematical models for inference",
    "section": "Inference for simple linear regression",
    "text": "Inference for simple linear regression\n\nCalculate a confidence interval for the slope, \\(\\beta_1\\)\nConduct a hypothesis test for the interval, \\(\\beta_1\\)"
  },
  {
    "objectID": "slides/lec-6.html#confidence-interval-via-bootstrapping",
    "href": "slides/lec-6.html#confidence-interval-via-bootstrapping",
    "title": "SLR: Mathematical models for inference",
    "section": "Confidence interval via bootstrapping",
    "text": "Confidence interval via bootstrapping\n\nBootstrap new samples from the original sample\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the bootstrapped slopes to construct a confidence interval"
  },
  {
    "objectID": "slides/lec-6.html#bootstrapping-pipeline-i",
    "href": "slides/lec-6.html#bootstrapping-pipeline-i",
    "title": "SLR: Mathematical models for inference",
    "section": "Bootstrapping pipeline I",
    "text": "Bootstrapping pipeline I\n\n# #| code-line-numbers: \"|1|3|4\"\n#| \nset.seed(119)\n\nduke_forest %&gt;%\n  specify(price ~ area)\n\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98 √ó 2\n     price  area\n     &lt;dbl&gt; &lt;dbl&gt;\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# ‚Ä¶ with 88 more rows"
  },
  {
    "objectID": "slides/lec-6.html#bootstrapping-pipeline-ii",
    "href": "slides/lec-6.html#bootstrapping-pipeline-ii",
    "title": "SLR: Mathematical models for inference",
    "section": "Bootstrapping pipeline II",
    "text": "Bootstrapping pipeline II\n\n# #| code-line-numbers: \"|5\"\n\nset.seed(119)\n\nduke_forest %&gt;%\n  specify(price ~ area) %&gt;%\n  generate(reps = 1000, type = \"bootstrap\")\n\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98,000 √ó 3\n# Groups:   replicate [1,000]\n   replicate   price  area\n       &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1         1  535000  2334\n 2         1  520000  2637\n 3         1  540000  2165\n 4         1  155000  1620\n 5         1  567000  3931\n 6         1  420000  1745\n 7         1  400000  4769\n 8         1  579000  2926\n 9         1  615000  2203\n10         1 1030000  4475\n# ‚Ä¶ with 97,990 more rows"
  },
  {
    "objectID": "slides/lec-6.html#bootstrapping-pipeline-iii",
    "href": "slides/lec-6.html#bootstrapping-pipeline-iii",
    "title": "SLR: Mathematical models for inference",
    "section": "Bootstrapping pipeline III",
    "text": "Bootstrapping pipeline III\n\n# #| code-line-numbers: \"|6\"\n\nset.seed(119)\n\nduke_forest %&gt;%\n  specify(price ~ area) %&gt;%\n  generate(reps = 1000, type = \"bootstrap\") %&gt;%\n  fit()\n\n# A tibble: 2,000 √ó 3\n# Groups:   replicate [1,000]\n   replicate term      estimate\n       &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1         1 intercept  200401.\n 2         1 area          122.\n 3         2 intercept  120000.\n 4         2 area          156.\n 5         3 intercept  190879.\n 6         3 area          126.\n 7         4 intercept  206842.\n 8         4 area          127.\n 9         5 intercept  211231.\n10         5 area          124.\n# ‚Ä¶ with 1,990 more rows"
  },
  {
    "objectID": "slides/lec-6.html#bootstrapping-pipeline-iv",
    "href": "slides/lec-6.html#bootstrapping-pipeline-iv",
    "title": "SLR: Mathematical models for inference",
    "section": "Bootstrapping pipeline IV",
    "text": "Bootstrapping pipeline IV\n\n# #| code-line-numbers: \"|3\"\n\nset.seed(119)\n\nboot_dist &lt;- duke_forest %&gt;%\n  specify(price ~ area) %&gt;%\n  generate(reps = 1000, type = \"bootstrap\") %&gt;%\n  fit()"
  },
  {
    "objectID": "slides/lec-6.html#visualize-the-bootstrap-distribution",
    "href": "slides/lec-6.html#visualize-the-bootstrap-distribution",
    "title": "SLR: Mathematical models for inference",
    "section": "Visualize the bootstrap distribution",
    "text": "Visualize the bootstrap distribution\n\n# #| code-line-numbers: \"|2\"\n\nboot_dist %&gt;%\n  filter(term == \"area\") %&gt;%\n  ggplot(aes(x = estimate)) +\n  geom_histogram(binwidth = 10)"
  },
  {
    "objectID": "slides/lec-6.html#compute-the-ci",
    "href": "slides/lec-6.html#compute-the-ci",
    "title": "SLR: Mathematical models for inference",
    "section": "Compute the CI",
    "text": "Compute the CI\nTwo methods:\n\n\nPercentile method\nStandard error method"
  },
  {
    "objectID": "slides/lec-6.html#but-first",
    "href": "slides/lec-6.html#but-first",
    "title": "SLR: Mathematical models for inference",
    "section": "But first‚Ä¶",
    "text": "But first‚Ä¶\n\nobs_fit &lt;- duke_forest %&gt;%\n  specify(price ~ area) %&gt;%\n  fit()\n\nobs_fit\n\n# A tibble: 2 √ó 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159."
  },
  {
    "objectID": "slides/lec-6.html#percentile-method",
    "href": "slides/lec-6.html#percentile-method",
    "title": "SLR: Mathematical models for inference",
    "section": "Percentile method",
    "text": "Percentile method\n\n# #| code-line-numbers: \"|4\"\n\nboot_dist %&gt;%\n  get_confidence_interval(\n    level = 0.95,\n    type = \"percentile\",\n    point_estimate = obs_fit\n  )\n\n# A tibble: 2 √ó 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          91.0     215.\n2 intercept -22046.   289004."
  },
  {
    "objectID": "slides/lec-6.html#standard-error-method",
    "href": "slides/lec-6.html#standard-error-method",
    "title": "SLR: Mathematical models for inference",
    "section": "Standard error method",
    "text": "Standard error method\n\n# #| code-line-numbers: \"|4\"\n\nboot_dist %&gt;%\n  get_confidence_interval(\n    level = 0.95,\n    type = \"se\",\n    point_estimate = obs_fit\n  )\n\n# A tibble: 2 √ó 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          96.1     223.\n2 intercept -39805.   273109."
  },
  {
    "objectID": "slides/lec-6.html#research-question-and-hypotheses",
    "href": "slides/lec-6.html#research-question-and-hypotheses",
    "title": "SLR: Mathematical models for inference",
    "section": "Research question and hypotheses",
    "text": "Research question and hypotheses\n\n‚ÄúDo the data provide sufficient evidence that \\(\\beta_1\\) (the true slope for the population) is different from 0?‚Äù\nNull hypothesis - \\(H_0: \\beta_1 = 0\\), there is no linear relationship between area and price\nAlternative hypothesis - \\(H_A: \\beta_1 \\ne 0\\), there is a linear relationship between area and price"
  },
  {
    "objectID": "slides/lec-6.html#hypothesis-testing-framework",
    "href": "slides/lec-6.html#hypothesis-testing-framework",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis testing framework",
    "text": "Hypothesis testing framework\n\nStart with a null hypothesis, \\(H_0\\) that represents the status quo\nSet an alternative hypothesis, \\(H_A\\) that represents the research question, i.e.¬†what we‚Äôre testing for\nConduct a hypothesis test under the assumption that the null hypothesis is true and calculate a p-value (probability of observed or more extreme outcome given that the null hypothesis is true)\n\nif the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, stick with the null hypothesis\nif they do, then reject the null hypothesis in favor of the alternative"
  },
  {
    "objectID": "slides/lec-6.html#quantify-the-variability-of-the-slope",
    "href": "slides/lec-6.html#quantify-the-variability-of-the-slope",
    "title": "SLR: Mathematical models for inference",
    "section": "Quantify the variability of the slope",
    "text": "Quantify the variability of the slope\nfor testing\n\nTwo approaches:\n\nVia simulation (what we‚Äôll review from lab)\nVia mathematical models (what we‚Äôll cover in the remainder of class)\n\nRandomizing to quantify the variability of the slope for the purpose of testing, under the assumption that the null hypothesis is true:\n\nSimulate new samples from the original sample via permutation\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the permuted slopes to conduct a hypothesis test"
  },
  {
    "objectID": "slides/lec-6.html#permutation-described",
    "href": "slides/lec-6.html#permutation-described",
    "title": "SLR: Mathematical models for inference",
    "section": "Permutation, described",
    "text": "Permutation, described\n\n\n\nSet the null hypothesis to be true, and measure the natural variability in the data due to sampling but not due to variables being correlated by permuting permute one variable to eliminate any existing relationship between the variables\nEach price value is randomly assigned to area of a given house, i.e.¬†area and price are no longer matched for a given house\n\n\n\n\n# A tibble: 98 √ó 3\n   price_Observed price_Permuted  area\n            &lt;dbl&gt;          &lt;dbl&gt; &lt;dbl&gt;\n 1        1520000         342500  6040\n 2        1030000         750000  4475\n 3         420000         645000  1745\n 4         680000         697500  2091\n 5         428500         428500  1772\n 6         456000         481000  1950\n 7        1270000         610000  3909\n 8         557450         680000  2841\n 9         697500         485000  3924\n10         650000         105000  2173\n# ‚Ä¶ with 88 more rows"
  },
  {
    "objectID": "slides/lec-6.html#permutation-visualized",
    "href": "slides/lec-6.html#permutation-visualized",
    "title": "SLR: Mathematical models for inference",
    "section": "Permutation, visualized",
    "text": "Permutation, visualized\n\n\n\nEach of the observed values for area (and for price) exist in both the observed data plot as well as the permuted price plot\nThe permutation removes the linear relationship between area and price"
  },
  {
    "objectID": "slides/lec-6.html#permutation-repeated",
    "href": "slides/lec-6.html#permutation-repeated",
    "title": "SLR: Mathematical models for inference",
    "section": "Permutation, repeated",
    "text": "Permutation, repeated\nRepeated permutations allow for quantifying the variability in the slope under the condition that there is no linear relationship (i.e., that the null hypothesis is true)"
  },
  {
    "objectID": "slides/lec-6.html#concluding-the-hypothesis-test",
    "href": "slides/lec-6.html#concluding-the-hypothesis-test",
    "title": "SLR: Mathematical models for inference",
    "section": "Concluding the hypothesis test",
    "text": "Concluding the hypothesis test\n\nIs the observed slope of \\(\\hat{\\beta_1} = 159\\) (or an even more extreme slope) a likely outcome under the null hypothesis that \\(\\beta = 0\\)? What does this mean for our original question: ‚ÄúDo the data provide sufficient evidence that \\(\\beta_1\\) (the true slope for the population) is different from 0?‚Äù"
  },
  {
    "objectID": "slides/lec-6.html#permutation-pipeline-i",
    "href": "slides/lec-6.html#permutation-pipeline-i",
    "title": "SLR: Mathematical models for inference",
    "section": "Permutation pipeline I",
    "text": "Permutation pipeline I\n\n# #| code-line-numbers: \"|1|3|4\"\n#| \nset.seed(1125)\n\nduke_forest %&gt;%\n  specify(price ~ area)\n\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98 √ó 2\n     price  area\n     &lt;dbl&gt; &lt;dbl&gt;\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# ‚Ä¶ with 88 more rows"
  },
  {
    "objectID": "slides/lec-6.html#permutation-pipeline-ii",
    "href": "slides/lec-6.html#permutation-pipeline-ii",
    "title": "SLR: Mathematical models for inference",
    "section": "Permutation pipeline II",
    "text": "Permutation pipeline II\n\n# #| code-line-numbers: \"|5\"\n\nset.seed(1125)\n\nduke_forest %&gt;%\n  specify(price ~ area) %&gt;%\n  hypothesize(null = \"independence\")\n\nResponse: price (numeric)\nExplanatory: area (numeric)\nNull Hypothesis: independence\n# A tibble: 98 √ó 2\n     price  area\n     &lt;dbl&gt; &lt;dbl&gt;\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# ‚Ä¶ with 88 more rows"
  },
  {
    "objectID": "slides/lec-6.html#permutation-pipeline-iii",
    "href": "slides/lec-6.html#permutation-pipeline-iii",
    "title": "SLR: Mathematical models for inference",
    "section": "Permutation pipeline III",
    "text": "Permutation pipeline III\n\n# #| code-line-numbers: \"|6\"\n\nset.seed(1125)\n\nduke_forest %&gt;%\n  specify(price ~ area) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  generate(reps = 1000, type = \"permute\")\n\nResponse: price (numeric)\nExplanatory: area (numeric)\nNull Hypothesis: independence\n# A tibble: 98,000 √ó 3\n# Groups:   replicate [1,000]\n     price  area replicate\n     &lt;dbl&gt; &lt;dbl&gt;     &lt;int&gt;\n 1  465000  6040         1\n 2  481000  4475         1\n 3 1020000  1745         1\n 4  520000  2091         1\n 5  592000  1772         1\n 6  650000  1950         1\n 7  473000  3909         1\n 8  705000  2841         1\n 9  785000  3924         1\n10  671500  2173         1\n# ‚Ä¶ with 97,990 more rows"
  },
  {
    "objectID": "slides/lec-6.html#permutation-pipeline-iv",
    "href": "slides/lec-6.html#permutation-pipeline-iv",
    "title": "SLR: Mathematical models for inference",
    "section": "Permutation pipeline IV",
    "text": "Permutation pipeline IV\n\n# #| code-line-numbers: \"|7\"\n\nset.seed(1125)\n\nduke_forest %&gt;%\n  specify(price ~ area) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  generate(reps = 1000, type = \"permute\") %&gt;%\n  fit()\n\n# A tibble: 2,000 √ó 3\n# Groups:   replicate [1,000]\n   replicate term       estimate\n       &lt;int&gt; &lt;chr&gt;         &lt;dbl&gt;\n 1         1 intercept 553355.  \n 2         1 area           2.35\n 3         2 intercept 635824.  \n 4         2 area         -27.3 \n 5         3 intercept 536072.  \n 6         3 area           8.57\n 7         4 intercept 598649.  \n 8         4 area         -13.9 \n 9         5 intercept 556202.  \n10         5 area           1.33\n# ‚Ä¶ with 1,990 more rows"
  },
  {
    "objectID": "slides/lec-6.html#permutation-pipeline-v",
    "href": "slides/lec-6.html#permutation-pipeline-v",
    "title": "SLR: Mathematical models for inference",
    "section": "Permutation pipeline V",
    "text": "Permutation pipeline V\n\n# #| code-line-numbers: \"|3\"\n\nset.seed(1125)\n\nnull_dist &lt;- duke_forest %&gt;%\n  specify(price ~ area) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  generate(reps = 1000, type = \"permute\") %&gt;%\n  fit()"
  },
  {
    "objectID": "slides/lec-6.html#visualize-the-null-distribution",
    "href": "slides/lec-6.html#visualize-the-null-distribution",
    "title": "SLR: Mathematical models for inference",
    "section": "Visualize the null distribution",
    "text": "Visualize the null distribution\n\n# #| code-line-numbers: \"|2\"\n\nnull_dist %&gt;%\n  filter(term == \"area\") %&gt;%\n  ggplot(aes(x = estimate)) +\n  geom_histogram(binwidth = 10, color = \"white\")"
  },
  {
    "objectID": "slides/lec-6.html#reason-around-the-p-value",
    "href": "slides/lec-6.html#reason-around-the-p-value",
    "title": "SLR: Mathematical models for inference",
    "section": "Reason around the p-value",
    "text": "Reason around the p-value\n\nIn a world where the there is no relationship between the area of a Duke Forest house and in its price (\\(\\beta_1 = 0\\)), what is the probability that we observe a sample of 98 houses where the slope fo the model predicting price from area is 159 or even more extreme?"
  },
  {
    "objectID": "slides/lec-6.html#compute-the-p-value",
    "href": "slides/lec-6.html#compute-the-p-value",
    "title": "SLR: Mathematical models for inference",
    "section": "Compute the p-value",
    "text": "Compute the p-value\n\nWhat does this warning mean?\n\n\nget_p_value(\n  null_dist,\n  obs_stat = obs_fit,\n  direction = \"two-sided\"\n)\n\nWarning: Please be cautious in reporting a p-value of 0. This result is an\napproximation based on the number of `reps` chosen in the `generate()` step. See\n`?get_p_value()` for more information.\n\nWarning: Please be cautious in reporting a p-value of 0. This result is an\napproximation based on the number of `reps` chosen in the `generate()` step. See\n`?get_p_value()` for more information.\n\n\n# A tibble: 2 √ó 2\n  term      p_value\n  &lt;chr&gt;       &lt;dbl&gt;\n1 area            0\n2 intercept       0"
  },
  {
    "objectID": "slides/lec-6.html#the-regression-model-revisited",
    "href": "slides/lec-6.html#the-regression-model-revisited",
    "title": "SLR: Mathematical models for inference",
    "section": "The regression model, revisited",
    "text": "The regression model, revisited\n\ndf_fit &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) %&gt;%\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.325\n53302.463\n2.188\n0.031\n\n\narea\n159.483\n18.171\n8.777\n0.000"
  },
  {
    "objectID": "slides/lec-6.html#ht-and-ci-recapped",
    "href": "slides/lec-6.html#ht-and-ci-recapped",
    "title": "SLR: Mathematical models for inference",
    "section": "HT and CI, recapped",
    "text": "HT and CI, recapped\n\nHypothesis test:\n\n\nDo the data provide sufficient evidence that \\(\\beta_1\\) (the true slope for the population) is different from 0?\nNull hypothesis - \\(H_0: \\beta_1 = 0\\), there is no linear relationship between area and price.\nAlternative hypothesis - \\(H_A: \\beta_1 \\ne 0\\), there is a linear relationship between area and price.\n\n\nConfidence interval: Provide a plausible range of values for \\(\\beta_1\\) at a given confidence level."
  },
  {
    "objectID": "slides/lec-6.html#ht-and-ci-revisited",
    "href": "slides/lec-6.html#ht-and-ci-revisited",
    "title": "SLR: Mathematical models for inference",
    "section": "HT and CI, revisited",
    "text": "HT and CI, revisited\n\nEarlier we computed a CI and conducted a HT via simulation:\n\nCI: Bootstrap the observed sample to simulate the distribution of the slope\nHT: Permute the observed sample to simulate the distribution of the slope under the assumption that the null hypothesis is true\n\nNow we‚Äôll do these based on theoretical results, i.e., by using the Central Limit Theorem to define the distribution of the slope and use features (shape, center, spread) of this distribution to compute bounds of the CI and the p-value for the HT"
  },
  {
    "objectID": "slides/lec-6.html#mathematical-representation-of-the-model",
    "href": "slides/lec-6.html#mathematical-representation-of-the-model",
    "title": "SLR: Mathematical models for inference",
    "section": "Mathematical representation of the model",
    "text": "Mathematical representation of the model\n\\[\n\\begin{aligned}\nY &= Model + Error \\\\\n&= f(X) + \\epsilon \\\\\n&= \\mu_{Y|X} + \\epsilon \\\\\n&= \\beta_0 + \\beta_1 X + \\epsilon\n\\end{aligned}\n\\]\nwhere the errors are independent and normally distributed:\n\nindependent: Knowing the error term for one observation doesn‚Äôt tell you anything about the error term for another observation\nnormally distributed: \\(\\epsilon \\sim N(0, \\sigma_\\epsilon^2)\\)"
  },
  {
    "objectID": "slides/lec-6.html#mathematical-representation-visualized",
    "href": "slides/lec-6.html#mathematical-representation-visualized",
    "title": "SLR: Mathematical models for inference",
    "section": "Mathematical representation, visualized",
    "text": "Mathematical representation, visualized\n\\[\nY|X \\sim N(\\beta_0 + \\beta_1 X, \\sigma_\\epsilon^2)\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean: \\(\\beta_0 + \\beta_1 X\\), the predicted value based on the regression model\nVariance: \\(\\sigma_\\epsilon^2\\), constant across the range of \\(X\\)\n\nHow do we estimate \\(\\sigma_\\epsilon^2\\)?"
  },
  {
    "objectID": "slides/lec-6.html#regression-standard-error",
    "href": "slides/lec-6.html#regression-standard-error",
    "title": "SLR: Mathematical models for inference",
    "section": "Regression standard error",
    "text": "Regression standard error\nOnce we fit the model, we can use the residuals to estimate the regression standard error (the spread of the distribution of the response, for a given value of the predictor variable):\n\\[\n\\hat{\\sigma}_\\epsilon = \\sqrt{\\frac{\\sum_\\limits{i=1}^n(y_i - \\hat{y}_i)^2}{n-2}} = \\sqrt{\\frac{\\sum_\\limits{i=1}^ne_i^2}{n-2}}\n\\]\n. . .\n\n\n\nWhy divide by \\(n - 2\\)?\nWhy do we care about the value of the regression standard error?"
  },
  {
    "objectID": "slides/lec-6.html#standard-error-of-hatbeta_1",
    "href": "slides/lec-6.html#standard-error-of-hatbeta_1",
    "title": "SLR: Mathematical models for inference",
    "section": "Standard error of \\(\\hat{\\beta}_1\\)",
    "text": "Standard error of \\(\\hat{\\beta}_1\\)\n\\[\nSE_{\\hat{\\beta}_1} = \\hat{\\sigma}_\\epsilon\\sqrt{\\frac{1}{(n-1)s_X^2}}\n\\]\n. . .\nor‚Ä¶\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "slides/lec-8.html",
    "href": "slides/lec-8.html",
    "title": "Multiple linear regression (MLR)",
    "section": "",
    "text": "Lab 3:\n\n\nAny questions about lab / teamwork?\nDue Friday, Feb 4 at 5pm\n\n\nExam 1:\n\n\nReleased Friday, Feb 4\nMultiple choice questions (mostly conceptual) + open-ended exercises (like lab + homework)\nOpen book, open internet, open questions to me + Rick (head TA) only\nNo communication with others or posting questions on the internet allowed\nWhat can you do to start preparing?\n\nReview readings, assignments, feedback returned\nOrganize your notes\nCome to office hours with questions\n\n\n\n\n\n\n\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(openintro)   # for the duke_forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(knitr)       # for pretty tables\nlibrary(patchwork)   # for laying out plots\nlibrary(GGally)      # for pairwise plots\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 20))"
  },
  {
    "objectID": "slides/lec-8.html#announcements",
    "href": "slides/lec-8.html#announcements",
    "title": "Multiple linear regression (MLR)",
    "section": "",
    "text": "Lab 3:\n\n\nAny questions about lab / teamwork?\nDue Friday, Feb 4 at 5pm\n\n\nExam 1:\n\n\nReleased Friday, Feb 4\nMultiple choice questions (mostly conceptual) + open-ended exercises (like lab + homework)\nOpen book, open internet, open questions to me + Rick (head TA) only\nNo communication with others or posting questions on the internet allowed\nWhat can you do to start preparing?\n\nReview readings, assignments, feedback returned\nOrganize your notes\nCome to office hours with questions"
  },
  {
    "objectID": "slides/lec-8.html#computational-setup",
    "href": "slides/lec-8.html#computational-setup",
    "title": "Multiple linear regression (MLR)",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(openintro)   # for the duke_forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(knitr)       # for pretty tables\nlibrary(patchwork)   # for laying out plots\nlibrary(GGally)      # for pairwise plots\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 20))"
  },
  {
    "objectID": "slides/lec-8.html#house-prices-in-levittown",
    "href": "slides/lec-8.html#house-prices-in-levittown",
    "title": "Multiple linear regression (MLR)",
    "section": "House prices in Levittown",
    "text": "House prices in Levittown\n\nThe data set contains the sales price and characteristics of 85 homes in Levittown, NY that sold between June 2010 and May 2011.\nLevittown was built right after WWII and was the first planned suburban community built using mass production techniques.\nThe article ‚ÄúLevittown, the prototypical American suburb ‚Äì a history of cities in 50 buildings, day 25‚Äù gives an overview of Levittown‚Äôs controversial history."
  },
  {
    "objectID": "slides/lec-8.html#analysis-goals",
    "href": "slides/lec-8.html#analysis-goals",
    "title": "Multiple linear regression (MLR)",
    "section": "Analysis goals",
    "text": "Analysis goals\n\nWe would like to use the characteristics of a house to understand variability in the sales price.\nTo do so, we will fit a multiple linear regression model.\nUsing our model, we can answers questions such as\n\n\nWhat is the relationship between the characteristics of a house in Levittown and its sale price?\nGiven its characteristics, what is the expected sale price of a house in Levittown?"
  },
  {
    "objectID": "slides/lec-8.html#the-data",
    "href": "slides/lec-8.html#the-data",
    "title": "Multiple linear regression (MLR)",
    "section": "The data",
    "text": "The data\n\nlevittown &lt;- read_csv(here::here(\"slides/data/homeprices.csv\"))\nlevittown\n\n# A tibble: 85 √ó 7\n   bedrooms bathrooms living_area lot_size year_built property_tax sale_price\n      &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;\n 1        4       1          1380     6000       1948         8360     350000\n 2        4       2          1761     7400       1951         5754     360000\n 3        4       2          1564     6000       1948         8982     350000\n 4        5       2          2904     9898       1949        11664     375000\n 5        5       2.5        1942     7788       1948         8120     370000\n 6        4       2          1830     6000       1948         8197     335000\n 7        4       1          1585     6000       1948         6223     295000\n 8        4       1           941     6800       1951         2448     250000\n 9        4       1.5        1481     6000       1948         9087     299990\n10        3       2          1630     5998       1948         9430     375000\n# ‚Ä¶ with 75 more rows"
  },
  {
    "objectID": "slides/lec-8.html#variables",
    "href": "slides/lec-8.html#variables",
    "title": "Multiple linear regression (MLR)",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\n\nbedrooms: Number of bedrooms\nbathrooms: Number of bathrooms\nliving_area: Total living area of the house (in square feet)\nlot_size: Total area of the lot (in square feet)\nyear_built: Year the house was built\nproperty_tax: Annual property taxes (in USD)\n\n\nResponse: sale_price: Sales price (in USD)"
  },
  {
    "objectID": "slides/lec-8.html#eda-response-variable",
    "href": "slides/lec-8.html#eda-response-variable",
    "title": "Multiple linear regression (MLR)",
    "section": "EDA: Response variable",
    "text": "EDA: Response variable"
  },
  {
    "objectID": "slides/lec-8.html#eda-predictor-variables",
    "href": "slides/lec-8.html#eda-predictor-variables",
    "title": "Multiple linear regression (MLR)",
    "section": "EDA: Predictor variables",
    "text": "EDA: Predictor variables"
  },
  {
    "objectID": "slides/lec-8.html#eda-response-vs.-predictors",
    "href": "slides/lec-8.html#eda-response-vs.-predictors",
    "title": "Multiple linear regression (MLR)",
    "section": "EDA: Response vs.¬†Predictors",
    "text": "EDA: Response vs.¬†Predictors"
  },
  {
    "objectID": "slides/lec-8.html#eda-all-variables",
    "href": "slides/lec-8.html#eda-all-variables",
    "title": "Multiple linear regression (MLR)",
    "section": "EDA: All variables",
    "text": "EDA: All variables\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggpairs(levittown) +\n  theme(\n    axis.text.y = element_text(size = 10),\n    axis.text.x = element_text(angle = 45, size = 10),\n    strip.text.y = element_text(angle = 0, hjust = 0)\n    )"
  },
  {
    "objectID": "slides/lec-8.html#single-vs.-multiple-predictors",
    "href": "slides/lec-8.html#single-vs.-multiple-predictors",
    "title": "Multiple linear regression (MLR)",
    "section": "Single vs.¬†multiple predictors",
    "text": "Single vs.¬†multiple predictors\nSo far we‚Äôve used a single predictor variable to understand variation in a quantitative response variable\n. . .\nNow we want to use multiple predictor variables to understand variation in a quantitative response variable"
  },
  {
    "objectID": "slides/lec-8.html#multiple-linear-regression-mlr",
    "href": "slides/lec-8.html#multiple-linear-regression-mlr",
    "title": "Multiple linear regression (MLR)",
    "section": "Multiple linear regression (MLR)",
    "text": "Multiple linear regression (MLR)\nBased on the analysis goals, we will use a multiple linear regression model of the following form\n\\[\n\\begin{aligned}\\hat{\\text{sale_price}} ~ = & ~\n\\hat{\\beta}_0 + \\hat{\\beta}_1 \\text{bedrooms} + \\hat{\\beta}_2 \\text{bathrooms} + \\hat{\\beta}_3 \\text{living_area} \\\\\n&+ \\hat{\\beta}_4 \\text{lot_size} + \\hat{\\beta}_5 \\text{year_built} + \\hat{\\beta}_6 \\text{property_tax}\\end{aligned}\n\\]\nSimilar to simple linear regression, this model assumes that at each combination of the predictor variables, the values sale_price follow a Normal distribution."
  },
  {
    "objectID": "slides/lec-8.html#regression-model",
    "href": "slides/lec-8.html#regression-model",
    "title": "Multiple linear regression (MLR)",
    "section": "Regression Model",
    "text": "Regression Model\nRecall: The simple linear regression model assumes\n\\[\nY|X\\sim N(\\beta_0 + \\beta_1 X, \\sigma_{\\epsilon}^2)\n\\]\n. . .\nSimilarly: The multiple linear regression model assumes\n\\[\nY|X_1, X_2, \\ldots, X_p \\sim N(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p, \\sigma_{\\epsilon}^2)\n\\]"
  },
  {
    "objectID": "slides/lec-8.html#the-mlr-model",
    "href": "slides/lec-8.html#the-mlr-model",
    "title": "Multiple linear regression (MLR)",
    "section": "The MLR model",
    "text": "The MLR model\nFor a given observation \\((x_{i1}, x_{i2} \\ldots, x_{ip}, y_i)\\)\n\\[\ny_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\dots + \\beta_p x_{ip} + \\epsilon_{i} \\hspace{8mm} \\epsilon_i \\sim N(0,\\sigma_\\epsilon^2)\n\\]"
  },
  {
    "objectID": "slides/lec-8.html#prediction",
    "href": "slides/lec-8.html#prediction",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction",
    "text": "Prediction\nAt any combination of the predictors, the mean value of the response \\(Y\\), is\n\\[\n\\mu_{Y|X_1, \\ldots, X_p} = \\beta_0 + \\beta_1 X_{1} + \\beta_2 X_2 + \\dots + \\beta_p X_p\n\\]\n. . .\nUsing multiple linear regression, we can estimate the mean response for any combination of predictors\n\\[\n\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X_{1} + \\hat{\\beta}_2 X_2 + \\dots + \\hat{\\beta}_p X_{p}\n\\]"
  },
  {
    "objectID": "slides/lec-8.html#model-fit",
    "href": "slides/lec-8.html#model-fit",
    "title": "Multiple linear regression (MLR)",
    "section": "Model fit",
    "text": "Model fit\n\nprice_fit &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  fit(sale_price ~ bedrooms + bathrooms + living_area + lot_size +\n        year_built + property_tax, data = levittown)\n\ntidy(price_fit) %&gt;%\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-7148818.957\n3820093.694\n-1.871\n0.065\n\n\nbedrooms\n-12291.011\n9346.727\n-1.315\n0.192\n\n\nbathrooms\n51699.236\n13094.170\n3.948\n0.000\n\n\nliving_area\n65.903\n15.979\n4.124\n0.000\n\n\nlot_size\n-0.897\n4.194\n-0.214\n0.831\n\n\nyear_built\n3760.898\n1962.504\n1.916\n0.059\n\n\nproperty_tax\n1.476\n2.832\n0.521\n0.604"
  },
  {
    "objectID": "slides/lec-8.html#model-equation",
    "href": "slides/lec-8.html#model-equation",
    "title": "Multiple linear regression (MLR)",
    "section": "Model equation",
    "text": "Model equation\n\\[\n\\begin{align}\\hat{\\text{price}} = & -7148818.957 - 12291.011 \\times \\text{bedrooms}\\\\[5pt]  \n&+ 51699.236 \\times \\text{bathrooms}  + 65.903 \\times \\text{living area}\\\\[5pt]\n&- 0.897 \\times \\text{lot size} +  3760.898 \\times \\text{year built}\\\\[5pt]\n&+ 1.476 \\times \\text{property tax}\n\\end{align}\n\\]"
  },
  {
    "objectID": "slides/lec-8.html#interpreting-hatbeta_j",
    "href": "slides/lec-8.html#interpreting-hatbeta_j",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting \\(\\hat{\\beta}_j\\)",
    "text": "Interpreting \\(\\hat{\\beta}_j\\)\n\nThe estimated coefficient \\(\\hat{\\beta}_j\\) is the expected change in the mean of \\(y\\) when \\(x_j\\) increases by one unit, holding the values of all other predictor variables constant.\n\n. . .\n\nExample: The estimated coefficient for living_area is 65.90. This means for each additional square foot of living area, we expect the sale price of a house in Levittown, NY to increase by $65.90, on average, holding all other predictor variables constant."
  },
  {
    "objectID": "slides/lec-8.html#prediction-1",
    "href": "slides/lec-8.html#prediction-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction",
    "text": "Prediction\n\nWhat is the predicted sale price for a house in Levittown, NY with 3 bedrooms, 1 bathroom, 1,050 square feet of living area, 6,000 square foot lot size, built in 1948 with $6,306 in property taxes?\n\n\n\n-7148818.957 - 12291.011 * 3 + 51699.236 * 1 + \n  65.903 * 1050 - 0.897 * 6000 + 3760.898 * 1948 + \n  1.476 * 6306\n\n[1] 265360.4\n\n\n. . .\nThe predicted sale price for a house in Levittown, NY with 3 bedrooms, 1 bathroom, 1050 square feet of living area, 6000 square foot lot size, built in 1948 with $6306 in property taxes is $265,360."
  },
  {
    "objectID": "slides/lec-8.html#prediction-revisit",
    "href": "slides/lec-8.html#prediction-revisit",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction, revisit",
    "text": "Prediction, revisit\nJust like with simple linear regression, we can use the predict() function in R to calculate the appropriate intervals for our predicted values:\n\nnew_house &lt;- tibble(\n  bedrooms = 3, bathrooms = 1, \n  living_area = 1050, lot_size = 6000, \n  year_built = 1948, property_tax = 6306\n  )\n\npredict(price_fit, new_house)\n\n# A tibble: 1 √ó 1\n    .pred\n    &lt;dbl&gt;\n1 265360."
  },
  {
    "objectID": "slides/lec-8.html#confidence-interval-for-hatmu_y",
    "href": "slides/lec-8.html#confidence-interval-for-hatmu_y",
    "title": "Multiple linear regression (MLR)",
    "section": "Confidence interval for \\(\\hat{\\mu}_y\\)",
    "text": "Confidence interval for \\(\\hat{\\mu}_y\\)\n\nCalculate a 95% confidence interval for the estimated mean price of houses in Levittown, NY with 3 bedrooms, 1 bathroom, 1050 square feet of living area, 6000 square foot lot size, built in 1948 with $6306 in property taxes.\n\n\n\npredict(price_fit, new_house, type = \"conf_int\", level = 0.95)\n\n# A tibble: 1 √ó 2\n  .pred_lower .pred_upper\n        &lt;dbl&gt;       &lt;dbl&gt;\n1     238482.     292239."
  },
  {
    "objectID": "slides/lec-8.html#prediction-interval-for-haty",
    "href": "slides/lec-8.html#prediction-interval-for-haty",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction interval for \\(\\hat{y}\\)",
    "text": "Prediction interval for \\(\\hat{y}\\)\n\nCalculate a 95% prediction interval for an individual house in Levittown, NY with 3 bedrooms, 1 bathroom, 1050 square feet of living area, 6000 square foot lot size, built in 1948 with $6306 in property taxes.\n\n\n\npredict(price_fit, new_house, type = \"pred_int\", level = 0.95)\n\n# A tibble: 1 √ó 2\n  .pred_lower .pred_upper\n        &lt;dbl&gt;       &lt;dbl&gt;\n1     167277.     363444."
  },
  {
    "objectID": "slides/lec-8.html#cautions",
    "href": "slides/lec-8.html#cautions",
    "title": "Multiple linear regression (MLR)",
    "section": "Cautions",
    "text": "Cautions\n\nDo not extrapolate! Because there are multiple predictor variables, there is the potential to extrapolate in many directions\nThe multiple regression model only shows association, not causality\n\nTo show causality, you must have a carefully designed experiment or carefully account for confounding variables in an observational study"
  },
  {
    "objectID": "slides/lec-8.html#recap",
    "href": "slides/lec-8.html#recap",
    "title": "Multiple linear regression (MLR)",
    "section": "Recap",
    "text": "Recap\n\n\nIntroduced multiple linear regression\nInterpreted a coefficient \\(\\hat{\\beta}_j\\)\nUsed the model to calculate predicted values and the corresponding intervals"
  },
  {
    "objectID": "supplemental/log-transformations.html",
    "href": "supplemental/log-transformations.html",
    "title": "Log Transformations in Linear Regression",
    "section": "",
    "text": "Note\n\n\n\nThe following supplemental notes were created by Dr.¬†Maria Tackett for STA 210. They are provided for students who want to dive deeper into the mathematics behind regression and reflect some of the material covered in STA 211: Mathematics of Regression. Additional supplemental notes will be added throughout the semester.\nThis document provides details about the model interpretation when the predictor and/or response variables are log-transformed. For simplicity, we will discuss transformations for the simple linear regression model as shown in Equation¬†1.\n\\[\n\\label{orig}\ny = \\beta_0 + \\beta_1 x\n\\tag{1}\\]\nAll results and interpretations can be easily extended to transformations in multiple regression models.\nNote: log refers to the natural logarithm."
  },
  {
    "objectID": "supplemental/log-transformations.html#log-transformation-on-the-response-variable",
    "href": "supplemental/log-transformations.html#log-transformation-on-the-response-variable",
    "title": "Log Transformations in Linear Regression",
    "section": "Log-transformation on the response variable",
    "text": "Log-transformation on the response variable\nSuppose we fit a linear regression model with \\(\\log(y)\\), the log-transformed \\(y\\), as the response variable. Under this model, we assume a linear relationship exists between \\(x\\) and \\(\\log(y)\\), such that \\(\\log(y) \\sim N(\\beta_0 + \\beta_1 x, \\sigma^2)\\) for some \\(\\beta_0\\), \\(\\beta_1\\) and \\(\\sigma^2\\). In other words, we can model the relationship between \\(x\\) and \\(\\log(y)\\) using the model in Equation¬†2.\n\\[\n\\log(y) = \\beta_0 + \\beta_1 x\n\\tag{2}\\]\nIf we interpret the model in terms of \\(\\log(y)\\), then we can use the usual interpretations for slope and intercept. When reporting results, however, it is best to give all interpretations in terms of the original response variable \\(y\\), since interpretations using log-transformed variables are often more difficult to truly understand.\nIn order to get back on the original scale, we need to use the exponential function (also known as the anti-log), \\(\\exp\\{x\\} = e^x\\). Therefore, we use the model in Equation¬†2 for interpretations and predictions, we will use Equation¬†3 to state our conclusions in terms of \\(y\\).\n\\[\n\\begin{aligned}\n&\\exp\\{\\log(y)\\} = \\exp\\{\\beta_0 + \\beta_1 x\\} \\\\[10pt]\n\\Rightarrow &y = \\exp\\{\\beta_0 + \\beta_1 x\\} \\\\[10pt]\n\\Rightarrow &y = \\exp\\{\\beta_0\\}\\exp\\{\\beta_1 x\\}\n\\end{aligned}\n\\tag{3}\\]\nIn order to interpret the slope and intercept, we need to first understand the relationship between the mean, median and log transformations.\n\nMean, Median, and Log Transformations\nSuppose we have a dataset y that contains the following observations:\n\n\n[1] 3 5 6 7 8\n\n\nIf we log-transform the values of y then calculate the mean and median, we have\n\n\n\n\n\nmean_log_y\nmedian_log_y\n\n\n\n\n1.70503\n1.79176\n\n\n\n\n\nIf we calculate the mean and median of y, then log-transform the mean and median, we have\n\n\n\n\n\nlog_mean\nlog_median\n\n\n\n\n1.75786\n1.79176\n\n\n\n\n\nThis is a simple illustration to show\n\n\\(\\text{Mean}[{\\log(y)}] \\neq \\log[\\text{Mean}(y)]\\) - the mean and log are not commutable\n\\(\\text{Median}[\\log(y)] = \\log[\\text{Median}(y)]\\) - the median and log are commutable\n\n\n\nInterpretaton of model coefficients\nUsing Equation¬†2, the mean \\(\\log(y)\\) for any given value of \\(x\\) is \\(\\beta_0 + \\beta_1 x\\); however, this does not indicate that the mean of \\(y = \\exp\\{\\beta_0 + \\beta_1 x\\}\\) (see previous section). From the assumptions of linear regression, we assume that for any given value of \\(x\\), the distribution of \\(\\log(y)\\) is Normal, and therefore symmetric. Thus the median of \\(\\log(y)\\) is equal to the mean of \\(\\log(y)\\), i.e \\(\\text{Median}(\\log(y)) = \\beta_0 + \\beta_1 x\\).\nSince the log and the median are commutable, \\(\\text{Median}(\\log(y)) = \\beta_0 + \\beta_1 x \\Rightarrow \\text{Median}(y) = \\exp\\{\\beta_0 + \\beta_1 x\\}\\). Thus, when we log-transform the response variable, the interpretation of the intercept and slope are in terms of the effect on the median of \\(y\\).\nIntercept: The intercept is expected median of \\(y\\) when the predictor variable equals 0. Therefore, when \\(x=0\\),\n\\[\n\\begin{aligned}\n&\\log(y) = \\beta_0 + \\beta_1 \\times 0 = \\beta_0 \\\\[10pt]\n\\Rightarrow &y = \\exp\\{\\beta_0\\}\n\\end{aligned}\n\\]\nInterpretation: When \\(x=0\\), the median of \\(y\\) is expected to be \\(\\exp\\{\\beta_0\\}\\).\nSlope: The slope is the expected change in the median of \\(y\\) when \\(x\\) increases by 1 unit. The change in the median of \\(y\\) is\n\\[\n\\exp\\{[\\beta_0 + \\beta_1 (x+1)] - [\\beta_0 + \\beta_1 x]\\} = \\frac{\\exp\\{\\beta_0 + \\beta_1 (x+1)\\}}{\\exp\\{\\beta_0 + \\beta_1 x\\}} = \\frac{\\exp\\{\\beta_0\\}\\exp\\{\\beta_1 x\\}\\exp\\{\\beta_1\\}}{\\exp\\{\\beta_0\\}\\exp\\{\\beta_1 x\\}} = \\exp\\{\\beta_1\\}\n\\]\nThus, the median of \\(y\\) for \\(x+1\\) is \\(\\exp\\{\\beta_1\\}\\) times the median of \\(y\\) for \\(x\\).\nInterpretation: When \\(x\\) increases by one unit, the median of \\(y\\) is expected to multiply by a factor of \\(\\exp\\{\\beta_1\\}\\)."
  },
  {
    "objectID": "supplemental/log-transformations.html#log-transformation-on-the-predictor-variable",
    "href": "supplemental/log-transformations.html#log-transformation-on-the-predictor-variable",
    "title": "Log Transformations in Linear Regression",
    "section": "Log-transformation on the predictor variable",
    "text": "Log-transformation on the predictor variable\nSuppose we fit a linear regression model with \\(\\log(x)\\), the log-transformed \\(x\\), as the predictor variable. Under this model, we assume a linear relationship exists between \\(\\log(x)\\) and \\(y\\), such that \\(y \\sim N(\\beta_0 + \\beta_1 \\log(x), \\sigma^2)\\) for some \\(\\beta_0\\), \\(\\beta_1\\) and \\(\\sigma^2\\). In other words, we can model the relationship between \\(\\log(x)\\) and \\(y\\) using the model in #eq-log-x.\n\\[\ny = \\beta_0 + \\beta_1 \\log(x)\n\\tag{4}\\]\nIntercept: The intercept is the mean of \\(y\\) when \\(\\log(x) = 0\\), i.e.¬†\\(x = 1\\).\nInterpretation: When \\(x = 1\\) \\((\\log(x) = 0)\\), the mean of \\(y\\) is expected to be \\(\\beta_0\\).\nSlope: The slope is interpreted in terms of the change in the mean of \\(y\\) when \\(x\\) is multiplied by a factor of \\(C\\), since \\(\\log(Cx) = \\log(x) + \\log(C)\\). Thus, when \\(x\\) is multiplied by a factor of \\(C\\), the change in the mean of \\(y\\) is\n\\[\n\\begin{aligned}\n[\\beta_0 + \\beta_1 \\log(Cx)] - [\\beta_0 + \\beta_1 \\log(x)] &= \\beta_1 [\\log(Cx) - \\log(x)] \\\\[10pt]\n& = \\beta_1[\\log(C) + \\log(x) - \\log(x)] \\\\[10pt]\n& = \\beta_1 \\log(C)\n\\end{aligned}\n\\]\nThus the mean of \\(y\\) changes by \\(\\beta_1 \\log(C)\\) units.\nInterpretation: When \\(x\\) is multiplied by a factor of \\(C\\), the mean of \\(y\\) is expected to change by \\(\\beta_1 \\log(C)\\) units. For example, if \\(x\\) is doubled, then the mean of \\(y\\) is expected to change by \\(\\beta_1 \\log(2)\\) units."
  },
  {
    "objectID": "supplemental/log-transformations.html#log-transformation-on-the-the-response-and-predictor-variable",
    "href": "supplemental/log-transformations.html#log-transformation-on-the-the-response-and-predictor-variable",
    "title": "Log Transformations in Linear Regression",
    "section": "Log-transformation on the the response and predictor variable",
    "text": "Log-transformation on the the response and predictor variable\nSuppose we fit a linear regression model with \\(\\log(x)\\), the log-transformed \\(x\\), as the predictor variable and \\(\\log(y)\\), the log-transformed \\(y\\), as the response variable. Under this model, we assume a linear relationship exists between \\(\\log(x)\\) and \\(\\log(y)\\), such that \\(\\log(y) \\sim N(\\beta_0 + \\beta_1 \\log(x), \\sigma^2)\\) for some \\(\\beta_0\\), \\(\\beta_1\\) and \\(\\sigma^2\\). In other words, we can model the relationship between \\(\\log(x)\\) and \\(\\log(y)\\) using the model in Equation¬†5.\n\\[\n\\log(y) = \\beta_0 + \\beta_1 \\log(x)\n\\tag{5}\\]\nBecause the response variable is log-transformed, the interpretations on the original scale will be in terms of the median of \\(y\\) (see the section on the log-transformed response variable for more detail).\nIntercept: The intercept is the mean of \\(y\\) when \\(\\log(x) = 0\\), i.e.¬†\\(x = 1\\). Therefore, when \\(\\log(x) = 0\\),\n\\[\n\\begin{aligned}\n&\\log(y) = \\beta_0 + \\beta_1 \\times 0 = \\beta_0 \\\\[10pt]\n\\Rightarrow &y = \\exp\\{\\beta_0\\}\n\\end{aligned}\n\\]\nInterpretation: When \\(x = 1\\) \\((\\log(x) = 0)\\), the median of \\(y\\) is expected to be \\(\\exp\\{\\beta_0\\}\\).\nSlope: The slope is interpreted in terms of the change in the median \\(y\\) when \\(x\\) is multiplied by a factor of \\(C\\), since \\(\\log(Cx) = \\log(x) + \\log(C)\\). Thus, when \\(x\\) is multiplied by a factor of \\(C\\), the change in the median of \\(y\\) is\n\\[\n\\begin{aligned}\n\\exp\\{[\\beta_0 + \\beta_1 \\log(Cx)] - [\\beta_0 + \\beta_1 \\log(x)]\\} &=\n\\exp\\{\\beta_1 [\\log(Cx) - \\log(x)]\\} \\\\[10pt]\n& = \\exp\\{\\beta_1[\\log(C) + \\log(x) - \\log(x)]\\} \\\\[10pt]\n& = \\exp\\{\\beta_1 \\log(C)\\} = C^{\\beta_1}\n\\end{aligned}\n\\]\nThus, the median of \\(y\\) for \\(Cx\\) is \\(C^{\\beta_1}\\) times the median of \\(y\\) for \\(x\\).\nInterpretation: When \\(x\\) is multiplied by a factor of \\(C\\), the median of \\(y\\) is expected to multiple by a factor of \\(C^{\\beta_1}\\). For example, if \\(x\\) is doubled, then the median of \\(y\\) is expected to multiply by \\(2^{\\beta_1}\\)."
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html",
    "href": "supplemental/model-diagnostics-matrix.html",
    "title": "Model Diagnostics",
    "section": "",
    "text": "Note\n\n\n\nThe following supplemental notes were created by Dr.¬†Maria Tackett for STA 210. They are provided for students who want to dive deeper into the mathematics behind regression and reflect some of the material covered in STA 211: Mathematics of Regression. Additional supplemental notes will be added throughout the semester.\nThis document discusses some of the mathematical details of the model diagnostics - leverage, standardized residuals, and Cook‚Äôs distance. We assume the reader knowledge of the matrix form for multiple linear regression. Please see Matrix Form of Linear Regression for a review."
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#introduction",
    "href": "supplemental/model-diagnostics-matrix.html#introduction",
    "title": "Model Diagnostics",
    "section": "Introduction",
    "text": "Introduction\nSuppose we have \\(n\\) observations. Let the \\(i^{th}\\) be \\((x_{i1}, \\ldots, x_{ip}, y_i)\\), such that \\(x_{i1}, \\ldots, x_{ip}\\) are the explanatory variables (predictors) and \\(y_i\\) is the response variable. We assume the data can be modeled using the least-squares regression model, such that the mean response for a given combination of explanatory variables follows the form in Equation¬†1.\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p\n\\tag{1}\\]\nWe can write the response for the \\(i^{th}\\) observation as shown in Equation¬†2.\n\\[\ny_i = \\beta_0 + \\beta_1 x_{i1} + \\dots + \\beta_p x_{ip} + \\epsilon_i\n\\tag{2}\\]\nsuch that \\(\\epsilon_i\\) is the amount \\(y_i\\) deviates from \\(\\mu\\{y|x_{i1}, \\ldots, x_{ip}\\}\\), the mean response for a given combination of explanatory variables. We assume each \\(\\epsilon_i \\sim N(0,\\sigma^2)\\), where \\(\\sigma^2\\) is a constant variance for the distribution of the response \\(y\\) for any combination of explanatory variables \\(x_1, \\ldots, x_p\\)."
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#matrix-form-for-the-regression-model",
    "href": "supplemental/model-diagnostics-matrix.html#matrix-form-for-the-regression-model",
    "title": "Model Diagnostics",
    "section": "Matrix Form for the Regression Model",
    "text": "Matrix Form for the Regression Model\nWe can represent the Equation¬†1 and Equation¬†2 using matrix notation. Let\n\\[\n\\mathbf{Y} = \\begin{bmatrix}y_1 \\\\ y_2 \\\\ \\vdots \\\\y_n\\end{bmatrix}\n\\hspace{15mm}\n\\mathbf{X} = \\begin{bmatrix}x_{11} & x_{12} & \\dots & x_{1p} \\\\\nx_{21} & x_{22} & \\dots & x_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\nx_{n1} & x_{n2} & \\dots & x_{np} \\end{bmatrix}\n\\hspace{15mm}\n\\boldsymbol{\\beta}= \\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\\\ \\vdots \\\\ \\beta_p \\end{bmatrix}\n\\hspace{15mm}\n\\boldsymbol{\\epsilon}= \\begin{bmatrix}\\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{bmatrix}\n\\tag{3}\\]\nThus,\n\\[\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\\]\nTherefore the estimated response for a given combination of explanatory variables and the associated residuals can be written as\n\\[\n\\hat{\\mathbf{Y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\hspace{10mm} \\mathbf{e} = \\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\n\\tag{4}\\]"
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#hat-matrix-leverage",
    "href": "supplemental/model-diagnostics-matrix.html#hat-matrix-leverage",
    "title": "Model Diagnostics",
    "section": "Hat Matrix & Leverage",
    "text": "Hat Matrix & Leverage\nRecall from the notes Matrix Form of Linear Regression that \\(\\hat{\\boldsymbol{\\beta}}\\) can be written as the following:\n\\[\n\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}\n\\tag{5}\\]\nCombining Equation¬†4 and Equation¬†5, we can write \\(\\hat{\\mathbf{Y}}\\) as the following:\n\\[\n\\begin{aligned}\n\\hat{\\mathbf{Y}} &= \\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\[10pt]\n&= \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}\\\\\n\\end{aligned}\n\\tag{6}\\]\nWe define the hat matrix as an \\(n \\times n\\) matrix of the form \\(\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\). Thus Equation¬†6 becomes\n\\[\n\\hat{\\mathbf{Y}} = \\mathbf{H}\\mathbf{Y}\n\\tag{7}\\]\nThe diagonal elements of the hat matrix are a measure of how far the predictor variables of each observation are from the means of the predictor variables. For example, \\(h_{ii}\\) is a measure of how far the values of the predictor variables for the \\(i^{th}\\) observation, \\(x_{i1}, x_{i2}, \\ldots, x_{ip}\\), are from the mean values of the predictor variables, \\(\\bar{x}_1, \\bar{x}_2, \\ldots, \\bar{x}_p\\). In the case of simple linear regression, the \\(i^{th}\\) diagonal, \\(h_{ii}\\), can be written as\n\\[\nh_{ii} =  \\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{\\sum_{j=1}^{n}(x_j-\\bar{x})^2}\n\\]\nWe call these diagonal elements, the leverage of each observation.\nThe diagonal elements of the hat matrix have the following properties:\n\n\\(0 \\leq h_ii \\leq 1\\)\n\\(\\sum\\limits_{i=1}^{n} h_{ii} = p+1\\), where \\(p\\) is the number of predictor variables in the model.\nThe mean hat value is \\(\\bar{h} = \\frac{\\sum\\limits_{i=1}^{n} h_{ii}}{n} = \\frac{p+1}{n}\\).\n\nUsing these properties, we consider a point to have high leverage if it has a leverage value that is more than 2 times the average. In other words, observations with leverage greater than \\(\\frac{2(p+1)}{n}\\) are considered to be high leverage points, i.e.¬†outliers in the predictor variables. We are interested in flagging high leverage points, because they may have an influence on the regression coefficients.\nWhen there are high leverage points in the data, the regression line will tend towards those points; therefore, one property of high leverage points is that they tend to have small residuals. We will show this by rewriting the residuals from Equation¬†4 using Equation¬†7.\n\\[\n\\begin{aligned}\n\\mathbf{e} &= \\mathbf{Y} - \\hat{\\mathbf{Y}} \\\\[10pt]\n& = \\mathbf{Y} - \\mathbf{H}\\mathbf{Y} \\\\[10pt]\n&= (1-\\mathbf{H})\\mathbf{Y}\n\\end{aligned}\n\\tag{8}\\]\nNote that the identity matrix and hat matrix are idempotent, i.e.¬†\\(\\mathbf{I}\\mathbf{I} = \\mathbf{I}\\), \\(\\mathbf{H}\\mathbf{H} = \\mathbf{H}\\). Thus, \\((\\mathbf{I} - \\mathbf{H})\\) is also idempotent. These matrices are also symmetric. Using these properties and Equation¬†8, we have that the variance-covariance matrix of the residuals \\(\\boldsymbol{e}\\), is\n\\[\n\\begin{aligned}\nVar(\\mathbf{e}) &= \\mathbf{e}\\mathbf{e}^T \\\\[10pt]\n&=  (1-\\mathbf{H})Var(\\mathbf{Y})^T(1-\\mathbf{H})^T \\\\[10pt]\n&= (1-\\mathbf{H})\\hat{\\sigma}^2(1-\\mathbf{H})^T  \\\\[10pt]\n&= \\hat{\\sigma}^2(1-\\mathbf{H})(1-\\mathbf{H})  \\\\[10pt]\n&= \\hat{\\sigma}^2(1-\\mathbf{H})\n\\end{aligned}\n\\tag{9}\\]\nwhere \\(\\hat{\\sigma}^2 = \\frac{\\sum_{i=1}^{n}e_i^2}{n-p-1}\\) is the estimated regression variance. Thus, the variance of the \\(i^{th}\\) residual is \\(Var(e_i) = \\hat{\\sigma}^2(1-h_{ii})\\). Therefore, the higher the leverage, the smaller the variance of the residual. Because the expected value of the residuals is 0, we conclude that points with high leverage tend to have smaller residuals than points with lower leverage."
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#standardized-residuals",
    "href": "supplemental/model-diagnostics-matrix.html#standardized-residuals",
    "title": "Model Diagnostics",
    "section": "Standardized Residuals",
    "text": "Standardized Residuals\nIn general, we standardize a value by shifting by the expected value and rescaling by the standard deviation (or standard error). Thus, the \\(i^{th}\\) standardized residual takes the form\n\\[\nstd.res_i = \\frac{e_i - E(e_i)}{SE(e_i)}\n\\]\nThe expected value of the residuals is 0, i.e.¬†\\(E(e_i) = 0\\). From Equation¬†9), the standard error of the residual is \\(SE(e_i) = \\hat{\\sigma}\\sqrt{1-h_{ii}}\\). Therefore,\n\\[\nstd.res_i = \\frac{e_i}{\\hat{\\sigma}\\sqrt{1-h_{ii}}}\n\\tag{10}\\]"
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#cooks-distance",
    "href": "supplemental/model-diagnostics-matrix.html#cooks-distance",
    "title": "Model Diagnostics",
    "section": "Cook‚Äôs Distance",
    "text": "Cook‚Äôs Distance\nCook‚Äôs distance is a measure of how much each observation influences the model coefficients, and thus the predicted values. The Cook‚Äôs distance for the \\(i^{th}\\) observation can be written as\n\\[\nD_i = \\frac{(\\hat{\\mathbf{Y}} -\\hat{\\mathbf{Y}}_{(i)})^T(\\hat{\\mathbf{Y}} -\\hat{\\mathbf{Y}}_{(i)})}{(p+1)\\hat{\\sigma}}\n\\tag{11}\\]\nwhere \\(\\hat{\\mathbf{Y}}_{(i)}\\) is the vector of predicted values from the model fitted when the \\(i^{th}\\) observation is deleted. Cook‚Äôs Distance can be calculated without deleting observations one at a time, since Equation¬†12 below is mathematically equivalent to Equation¬†11.\n\\[\nD_i = \\frac{1}{p+1}std.res_i^2\\Bigg[\\frac{h_{ii}}{(1-h_{ii})}\\Bigg] = \\frac{e_i^2}{(p+1)\\hat{\\sigma}^2(1-h_{ii})}\\Bigg[\\frac{h_{ii}}{(1-h_{ii})}\\Bigg]\n\\tag{12}\\]"
  },
  {
    "objectID": "supplemental/slr-derivations.html",
    "href": "supplemental/slr-derivations.html",
    "title": "Deriving the Least-Squares Estimates for Simple Linear Regression",
    "section": "",
    "text": "Note\n\n\n\nThe following supplemental notes were created by Dr.¬†Maria Tackett for STA 210. They are provided for students who want to dive deeper into the mathematics behind regression and reflect some of the material covered in STA 211: Mathematics of Regression. Additional supplemental notes will be added throughout the semester.\n\n\nThis document contains the mathematical details for deriving the least-squares estimates for slope (\\(\\beta_1\\)) and intercept (\\(\\beta_0\\)). We obtain the estimates, \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\) by finding the values that minimize the sum of squared residuals, as shown in Equation¬†1.\n\\[\nSSR = \\sum\\limits_{i=1}^{n}[y_i - \\hat{y}_i]^2 = [y_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i)]^2 = [y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i]^2\n\\tag{1}\\]\nRecall that we can find the values of \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\) that minimize /eq-ssr by taking the partial derivatives of Equation¬†1 and setting them to 0. Thus, the values of \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\) that minimize the respective partial derivative also minimize the sum of squared residuals. The partial derivatives are shown in Equation¬†2.\n\\[\n\\begin{aligned}\n\\frac{\\partial \\text{SSR}}{\\partial \\hat{\\beta}_1} &= -2 \\sum\\limits_{i=1}^{n}x_i(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i)  \\\\\n\\frac{\\partial \\text{SSR}}{\\partial \\hat{\\beta}_0} &= -2 \\sum\\limits_{i=1}^{n}(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i)\n\\end{aligned}\n\\tag{2}\\]\nThe derivation of deriving \\(\\hat{\\beta}_0\\) is shown in Equation¬†3.\n\\[\n\\begin{aligned}\\frac{\\partial \\text{SSR}}{\\partial \\hat{\\beta}_0} &= -2 \\sum\\limits_{i=1}^{n}(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i) = 0 \\\\&\\Rightarrow -\\sum\\limits_{i=1}^{n}(y_i + \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i) = 0 \\\\&\\Rightarrow - \\sum\\limits_{i=1}^{n}y_i + n\\hat{\\beta}_0 + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i = 0 \\\\&\\Rightarrow n\\hat{\\beta}_0  = \\sum\\limits_{i=1}^{n}y_i - \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i \\\\&\\Rightarrow \\hat{\\beta}_0  = \\frac{1}{n}\\Big(\\sum\\limits_{i=1}^{n}y_i - \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i\\Big)\\\\&\\Rightarrow \\hat{\\beta}_0  = \\bar{y} - \\hat{\\beta}_1 \\bar{x} \\\\\\end{aligned}\n\\tag{3}\\]\nThe derivation of \\(\\hat{\\beta}_1\\) using the \\(\\hat{\\beta}_0\\) we just derived is shown in Equation¬†4.\n\\[\n\\begin{aligned}&\\frac{\\partial \\text{SSR}}{\\partial \\hat{\\beta}_1} = -2 \\sum\\limits_{i=1}^{n}x_i(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i) = 0  \\\\&\\Rightarrow -\\sum\\limits_{i=1}^{n}x_iy_i + \\hat{\\beta}_0\\sum\\limits_{i=1}^{n}x_i + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = 0 \\\\\\text{(Fill in }\\hat{\\beta}_0\\text{)}&\\Rightarrow -\\sum\\limits_{i=1}^{n}x_iy_i + (\\bar{y} - \\hat{\\beta}_1\\bar{x})\\sum\\limits_{i=1}^{n}x_i + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = 0 \\\\&\\Rightarrow  (\\bar{y} - \\hat{\\beta}_1\\bar{x})\\sum\\limits_{i=1}^{n}x_i + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = \\sum\\limits_{i=1}^{n}x_iy_i \\\\&\\Rightarrow \\bar{y}\\sum\\limits_{i=1}^{n}x_i - \\hat{\\beta}_1\\bar{x}\\sum\\limits_{i=1}^{n}x_i + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = \\sum\\limits_{i=1}^{n}x_iy_i \\\\&\\Rightarrow n\\bar{y}\\bar{x} - \\hat{\\beta}_1n\\bar{x}^2 + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = \\sum\\limits_{i=1}^{n}x_iy_i \\\\&\\Rightarrow \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 - \\hat{\\beta}_1n\\bar{x}^2  = \\sum\\limits_{i=1}^{n}x_iy_i - n\\bar{y}\\bar{x} \\\\&\\Rightarrow \\hat{\\beta}_1\\Big(\\sum\\limits_{i=1}^{n}x_i^2 -n\\bar{x}^2\\Big)  = \\sum\\limits_{i=1}^{n}x_iy_i - n\\bar{y}\\bar{x} \\\\ &\\hat{\\beta}_1 = \\frac{\\sum\\limits_{i=1}^{n}x_iy_i - n\\bar{y}\\bar{x}}{\\sum\\limits_{i=1}^{n}x_i^2 -n\\bar{x}^2}\\end{aligned}\n\\tag{4}\\]\nTo write \\(\\hat{\\beta}_1\\) in a form that‚Äôs more recognizable, we will use the following:\n\\[\n\\sum x_iy_i - n\\bar{y}\\bar{x} = \\sum(x - \\bar{x})(y - \\bar{y}) = (n-1)\\text{Cov}(x,y)\n\\tag{5}\\]\n\\[\n\\sum x_i^2 - n\\bar{x}^2 - \\sum(x - \\bar{x})^2 = (n-1)s_x^2\n\\tag{6}\\]\nwhere \\(\\text{Cov}(x,y)\\) is the covariance of \\(x\\) and \\(y\\), and \\(s_x^2\\) is the sample variance of \\(x\\) (\\(s_x\\) is the sample standard deviation).\nThus, applying Equation¬†5 and Equation¬†6, we have\n\\[\n\\begin{aligned}\\hat{\\beta}_1 &= \\frac{\\sum\\limits_{i=1}^{n}x_iy_i - n\\bar{y}\\bar{x}}{\\sum\\limits_{i=1}^{n}x_i^2 -n\\bar{x}^2} \\\\&= \\frac{\\sum\\limits_{i=1}^{n}(x-\\bar{x})(y-\\bar{y})}{\\sum\\limits_{i=1}^{n}(x-\\bar{x})^2}\\\\&= \\frac{(n-1)\\text{Cov}(x,y)}{(n-1)s_x^2}\\\\&= \\frac{\\text{Cov}(x,y)}{s_x^2}\\end{aligned}\n\\tag{7}\\]\nThe correlation between \\(x\\) and \\(y\\) is \\(r = \\frac{\\text{Cov}(x,y)}{s_x s_y}\\). Thus, \\(\\text{Cov}(x,y) = r s_xs_y\\). Plugging this into Equation¬†7, we have\n\\[\n\\hat{\\beta}_1 = \\frac{\\text{Cov}(x,y)}{s_x^2} = r\\frac{s_ys_x}{s_x^2} = r\\frac{s_y}{s_x}\n\\tag{8}\\]"
  },
  {
    "objectID": "weeks/week-10.html",
    "href": "weeks/week-10.html",
    "title": "Week 10",
    "section": "",
    "text": "Important\n\n\n\nDue date: Project proposal due Fri, Mar 18 at 5:00 pm."
  },
  {
    "objectID": "weeks/week-10.html#prepare",
    "href": "weeks/week-10.html#prepare",
    "title": "Week 10",
    "section": "Prepare",
    "text": "Prepare\nüìñ Read Introduction to Modern Statistics, Chp 9: Logistic regression"
  },
  {
    "objectID": "weeks/week-10.html#participate",
    "href": "weeks/week-10.html#participate",
    "title": "Week 10",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lecture 18 - Logistic regression\nüñ•Ô∏è Lecture 19 - Probabilities, odds, odds ratios"
  },
  {
    "objectID": "weeks/week-10.html#practice",
    "href": "weeks/week-10.html#practice",
    "title": "Week 10",
    "section": "Practice",
    "text": "Practice\nüìã Application Exercise 9 - Odds"
  },
  {
    "objectID": "weeks/week-10.html#perform",
    "href": "weeks/week-10.html#perform",
    "title": "Week 10",
    "section": "Perform",
    "text": "Perform\n‚úçÔ∏è HW 3 - Logistic regression and log transformation\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-12.html",
    "href": "weeks/week-12.html",
    "title": "Week 12",
    "section": "",
    "text": "Important\n\n\n\nDue dates: None."
  },
  {
    "objectID": "weeks/week-12.html#prepare",
    "href": "weeks/week-12.html#prepare",
    "title": "Week 12",
    "section": "Prepare",
    "text": "Prepare\nüìñ Read Introduction to Modern Statistics, Chp 26: Inference for logistic regression"
  },
  {
    "objectID": "weeks/week-12.html#participate",
    "href": "weeks/week-12.html#participate",
    "title": "Week 12",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lecture 22 - LR: Inference + conditions\nüñ•Ô∏è Lecture 23 - Multinomial logistic regression (MultiLR)"
  },
  {
    "objectID": "weeks/week-12.html#practice",
    "href": "weeks/week-12.html#practice",
    "title": "Week 12",
    "section": "Practice",
    "text": "Practice\nNo application exercises this week."
  },
  {
    "objectID": "weeks/week-12.html#perform",
    "href": "weeks/week-12.html#perform",
    "title": "Week 12",
    "section": "Perform",
    "text": "Perform\n‚úçÔ∏è HW 4 - Multinomial logistic regression\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-14.html",
    "href": "weeks/week-14.html",
    "title": "Week 14",
    "section": "",
    "text": "Important\n\n\n\nDue dates: Friday, April 15 - Project peer review of drafts"
  },
  {
    "objectID": "weeks/week-14.html#participate",
    "href": "weeks/week-14.html#participate",
    "title": "Week 14",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lecture 26 - MultiLR: Predictive models (cont.)\nüñ•Ô∏è Lecture 27 - Exam 3 Review"
  },
  {
    "objectID": "weeks/week-14.html#practice",
    "href": "weeks/week-14.html#practice",
    "title": "Week 14",
    "section": "Practice",
    "text": "Practice\nüìã Application Exercise 12 - Exam 3 Review"
  },
  {
    "objectID": "weeks/week-14.html#perform",
    "href": "weeks/week-14.html#perform",
    "title": "Week 14",
    "section": "Perform",
    "text": "Perform\n‚úçÔ∏è Project - Peer review of drafts\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-2.html",
    "href": "weeks/week-2.html",
    "title": "Week 2",
    "section": "",
    "text": "Important\n\n\n\n\nClasses are virtual this week. Find Zoom links here.\nDue dates:\n\nLab 1: Fri, Jan 14, 5pm ET\nAE 1: Sun, Jan 16, 11:59pm ET"
  },
  {
    "objectID": "weeks/week-2.html#prepare",
    "href": "weeks/week-2.html#prepare",
    "title": "Week 2",
    "section": "Prepare",
    "text": "Prepare\nüìñ Read Introduction to Modern Statistics, Chp 7: Linear regression with a single predictor"
  },
  {
    "objectID": "weeks/week-2.html#participate",
    "href": "weeks/week-2.html#participate",
    "title": "Week 2",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lab 1 - Meet the toolkit\nüñ•Ô∏è Lecture 2 - Simple linear regression\nüñ•Ô∏è Lecture 3 - Model fitting in R with tidymodels"
  },
  {
    "objectID": "weeks/week-2.html#practice",
    "href": "weeks/week-2.html#practice",
    "title": "Week 2",
    "section": "Practice",
    "text": "Practice\nüìã Application Exercise 1 - Bike rentals in DC (Post-class note: complete only Part 1 - Daily counts and temperature)"
  },
  {
    "objectID": "weeks/week-2.html#perform",
    "href": "weeks/week-2.html#perform",
    "title": "Week 2",
    "section": "Perform",
    "text": "Perform\n‚å®Ô∏è Lab 1 - Meet the toolkit\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-4.html",
    "href": "weeks/week-4.html",
    "title": "Week 4",
    "section": "",
    "text": "Important\n\n\n\n\nIf you can‚Äôt be in class for the lectures, you can watch the live stream or watch the recording later on Panopto.\nDue dates:\n\nHW 1: Fri, Jan 28, 5pm ET\nLab 1: Fri, Jan 28, 5pm ET"
  },
  {
    "objectID": "weeks/week-4.html#prepare",
    "href": "weeks/week-4.html#prepare",
    "title": "Week 4",
    "section": "Prepare",
    "text": "Prepare\nüìñ Read Introduction to Modern Statistics, Sec 24.4: Mathematical model for testing the slope\nüìñ Read Introduction to Modern Statistics, Sec 24.5: Mathematical model, interval for the slope\nüìñ Read Introduction to Modern Statistics, Sec 24.6: Checking model conditions\nüìñ Read Introduction to Modern Statistics, Sec 24.7: Chapter review"
  },
  {
    "objectID": "weeks/week-4.html#participate",
    "href": "weeks/week-4.html#participate",
    "title": "Week 4",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lab 2 - College scorecard\nüñ•Ô∏è Lecture 6 - SLR: Mathematical models for inference\nüñ•Ô∏è Lecture 7 - SLR: Model diagnostics"
  },
  {
    "objectID": "weeks/week-4.html#practice",
    "href": "weeks/week-4.html#practice",
    "title": "Week 4",
    "section": "Practice",
    "text": "Practice\nüìã Application Exercise 3 - Checking model conditions"
  },
  {
    "objectID": "weeks/week-4.html#perform",
    "href": "weeks/week-4.html#perform",
    "title": "Week 4",
    "section": "Perform",
    "text": "Perform\n‚å®Ô∏è Lab 2 - College scorecard\n‚úçÔ∏è HW 1 - In-person voting trends\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-6.html",
    "href": "weeks/week-6.html",
    "title": "Week 6",
    "section": "",
    "text": "Important\n\n\n\nDue dates: Exam 1 - Mon, Feb 7 at 11:59pm"
  },
  {
    "objectID": "weeks/week-6.html#prepare",
    "href": "weeks/week-6.html#prepare",
    "title": "Week 6",
    "section": "Prepare",
    "text": "Prepare\nNo reading (take a break after the exam! üò¥)"
  },
  {
    "objectID": "weeks/week-6.html#participate",
    "href": "weeks/week-6.html#participate",
    "title": "Week 6",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lecture 10 - MLR: Types of predictors\nüñ•Ô∏è Lecture 11 - MLR: Model comparison"
  },
  {
    "objectID": "weeks/week-6.html#practice",
    "href": "weeks/week-6.html#practice",
    "title": "Week 6",
    "section": "Practice",
    "text": "Practice\nNo application exercises"
  },
  {
    "objectID": "weeks/week-6.html#perform",
    "href": "weeks/week-6.html#perform",
    "title": "Week 6",
    "section": "Perform",
    "text": "Perform\nNo lab\n‚úÖ Exam 1\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-8.html",
    "href": "weeks/week-8.html",
    "title": "Week 8",
    "section": "",
    "text": "Important\n\n\n\nDue date: Lab 4 - Friday, Feb 25"
  },
  {
    "objectID": "weeks/week-8.html#prepare",
    "href": "weeks/week-8.html#prepare",
    "title": "Week 8",
    "section": "Prepare",
    "text": "Prepare\nüìñ Read Tidy Modeling in R Chp 10: Resampling for evaluating performance"
  },
  {
    "objectID": "weeks/week-8.html#participate",
    "href": "weeks/week-8.html#participate",
    "title": "Week 8",
    "section": "Participate",
    "text": "Participate\nüñ•Ô∏è Lecture 14 - MLR: Cross validation\nüñ•Ô∏è Lecture 15 - Exam 2 review"
  },
  {
    "objectID": "weeks/week-8.html#practice",
    "href": "weeks/week-8.html#practice",
    "title": "Week 8",
    "section": "Practice",
    "text": "Practice\nApplication Exercise 6 - The office - CV\nApplication Exercise 7 - Exam 2 Review"
  },
  {
    "objectID": "weeks/week-8.html#perform",
    "href": "weeks/week-8.html#perform",
    "title": "Week 8",
    "section": "Perform",
    "text": "Perform\n‚å®Ô∏è Lab 4 - The Office, another look\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "slides/lec-1.html#meet-the-professor",
    "href": "slides/lec-1.html#meet-the-professor",
    "title": "Welcome to STA 210!",
    "section": "Meet the professor",
    "text": "Meet the professor\n\n\n\n\n\nDr.¬†Mine √áetinkaya-Rundel (she/her)\n\n\n\n\nProfessor of the Practice & Director of Undergraduate Studies, Department of Statistical Science\nAffiliated Faculty, Computational Media, Arts & Cultures\nFind out more at mine-cr.com"
  },
  {
    "objectID": "slides/lec-1.html#meet-the-tas",
    "href": "slides/lec-1.html#meet-the-tas",
    "title": "Welcome to STA 210!",
    "section": "Meet the TAs",
    "text": "Meet the TAs\n\nMartha Aboagye (she/her, UG)\nRich Fremgen (he/him, MS)\nEmily Gentles (she/her, MS)\nSara Mehta (she/her, UG)\nRick Presman (he/him, PhD)\nShari Tian (she/her, UG)\nAaditya Warrier (he/him, UG)"
  },
  {
    "objectID": "slides/lec-1.html#check-out-conversations",
    "href": "slides/lec-1.html#check-out-conversations",
    "title": "Welcome to STA 210!",
    "section": "Check out Conversations",
    "text": "Check out Conversations\n\nGo to Conversations üí¨\nAnswer the discussion question: How are you doing?"
  },
  {
    "objectID": "slides/lec-1.html#what-is-regression-analysis",
    "href": "slides/lec-1.html#what-is-regression-analysis",
    "title": "Welcome to STA 210!",
    "section": "What is regression analysis",
    "text": "What is regression analysis\n\n\n‚ÄúIn statistical modeling, regression analysis is a set of statistical processes for estimating the relationships among variables. It includes many techniques for modeling and analyzing several variables, when the focus is on the relationship between a dependent variable and one or more independent variables (or predictors). More specifically, regression analysis helps one understand how the typical value of the dependent variable (or ‚Äòcriterion variable‚Äô) changes when any one of the independent variables is varied, while the other independent variables are held fixed.‚Äù\n\n\nSource: Wikipedia"
  },
  {
    "objectID": "slides/lec-1.html#course-faq",
    "href": "slides/lec-1.html#course-faq",
    "title": "Welcome to STA 210!",
    "section": "Course FAQ",
    "text": "Course FAQ\n\n\nWhat background is assumed for the course? Introductory statistics or probability course.\nWill we be doing computing? Yes. We will use R.\nWill we learn the mathematical theory of regression? Yes and No.¬†The course is primarily focused on application; however, we will discuss some of the mathematics of simple linear regression. The 1-credit course STA 211: Mathematics of Regression you can take simultaneously / after dives into more of the mathematics."
  },
  {
    "objectID": "slides/lec-1.html#course-learning-objectives",
    "href": "slides/lec-1.html#course-learning-objectives",
    "title": "Welcome to STA 210!",
    "section": "Course learning objectives",
    "text": "Course learning objectives\n\nAnalyze real-world data to answer questions about multivariable relationships.\nFit and evaluate linear and logistic regression models.\nAssess whether a proposed model is appropriate and describe its limitations.\nUse Quarto to write reproducible reports and GitHub for version control and collaboration.\nCommunicate results from statistical analyses to a general audience."
  },
  {
    "objectID": "slides/lec-1.html#examples-of-regression-in-practice",
    "href": "slides/lec-1.html#examples-of-regression-in-practice",
    "title": "Welcome to STA 210!",
    "section": "Examples of regression in practice",
    "text": "Examples of regression in practice\n\n\nNew Yorkers Will Pay $56 A Month To Trim A Minute Off Their Commute\nHow FiveThirtyEight‚Äôs 2020 Presidential Forecast Works ‚Äî And What‚Äôs Different Because Of COVID-19\nEffect of Forensic Evidence on Criminal Justice Case Processing\nWhy it‚Äôs so freaking hard to make a good COVID-19 model"
  },
  {
    "objectID": "slides/lec-1.html#homepage",
    "href": "slides/lec-1.html#homepage",
    "title": "Welcome to STA 210!",
    "section": "Homepage",
    "text": "Homepage\nsta210-s22.github.io/website\n\nAll course materials\nLinks to Sakai, GitHub, RStudio containers, etc.\nLet‚Äôs take a tour!"
  },
  {
    "objectID": "slides/lec-1.html#course-toolkit",
    "href": "slides/lec-1.html#course-toolkit",
    "title": "Welcome to STA 210!",
    "section": "Course toolkit",
    "text": "Course toolkit\nAll linked from the course website:\n\nGitHub organization: github.com/sta210-s22\nRStudio containers: cmgr.oit.duke.edu/containers\nDiscussion forum: Conversations\nAssignment submission and feedback: Gradescope\n\n\n\n\n\n\n\nImportant\n\n\nReserve an RStudio Container (titled STA 210) before lab on Monday!"
  },
  {
    "objectID": "slides/lec-1.html#activities-prepare-participate-practice-perform",
    "href": "slides/lec-1.html#activities-prepare-participate-practice-perform",
    "title": "Welcome to STA 210!",
    "section": "Activities: Prepare, Participate, Practice, Perform",
    "text": "Activities: Prepare, Participate, Practice, Perform\n\nPrepare: Introduce new content and prepare for lectures by completing the readings (and sometimes watching the videos)\nParticipate: Attend and actively participate in lectures and labs, office hours, team meetings\nPractice: Practice applying statistical concepts and computing with application exercises during lecture, graded for completion\nPerform: Put together what you‚Äôve learned to analyze real-world data\n\nLab assignments x 7 (first individual, later team-based)\nHomework assignments x 5 (individual)\nThree take-home exams\nTerm project presented during the final exam period"
  },
  {
    "objectID": "slides/lec-1.html#cadence",
    "href": "slides/lec-1.html#cadence",
    "title": "Welcome to STA 210!",
    "section": "Cadence",
    "text": "Cadence\n\n\nLabs: Start and make large progress on Monday in lab section, finish up by Friday 5pm of that week\nHWs: Posted Friday morning, due following Friday 5pm\nExams: Exam review Thursday in class, exam posted Friday morning, no lab on Monday of following week, due Monday 11:59pm\nProject: Deadlines throughout the semester, with some lab and lecture time dedicated to working on them, and most work done in teams outside of class"
  },
  {
    "objectID": "slides/lec-1.html#teams",
    "href": "slides/lec-1.html#teams",
    "title": "Welcome to STA 210!",
    "section": "Teams",
    "text": "Teams\n\nTeam assignments\n\nAssigned by me\nApplication exercises, labs, and project\nPeer evaluation during teamwork and after completion\n\nExpectations and roles\n\nEveryone is expected to contribute equal effort\nEveryone is expected to understand all code turned in\nIndividual contribution evaluated by peer evaluation, commits, etc."
  },
  {
    "objectID": "slides/lec-1.html#grading",
    "href": "slides/lec-1.html#grading",
    "title": "Welcome to STA 210!",
    "section": "Grading",
    "text": "Grading\n\n\n\nCategory\nPercentage\n\n\n\n\nApplication exercises\n3%\n\n\nHomework\n35% (7% x 5)\n\n\nProject\n15%\n\n\nLab\n14% (2% x 7)\n\n\nExam 01\n10%\n\n\nExam 02\n10%\n\n\nExam 03\n10%\n\n\nTeamwork\n3%\n\n\n\nSee course syllabus for how the final letter grade will be determined."
  },
  {
    "objectID": "slides/lec-1.html#support",
    "href": "slides/lec-1.html#support",
    "title": "Welcome to STA 210!",
    "section": "Support",
    "text": "Support\n\nAttend office hours\nAsk and answer questions on the discussion forum\nReserve email for questions on personal matters and/or grades\nRead the course support page"
  },
  {
    "objectID": "slides/lec-1.html#announcements",
    "href": "slides/lec-1.html#announcements",
    "title": "Welcome to STA 210!",
    "section": "Announcements",
    "text": "Announcements\n\nPosted on Sakai (Announcements tool) and sent via email, be sure to check both regularly\nI‚Äôll assume that you‚Äôve read an announcement by the next ‚Äúbusiness‚Äù day\nI‚Äôll (try my best to) send a weekly update announcement each Friday, outlining the plan for the following week and reminding you what you need to do to prepare, practice, and perform"
  },
  {
    "objectID": "slides/lec-1.html#diversity-inclusion",
    "href": "slides/lec-1.html#diversity-inclusion",
    "title": "Welcome to STA 210!",
    "section": "Diversity + inclusion",
    "text": "Diversity + inclusion\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students‚Äô learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\n\nIf you have a name that differs from those that appear in your official Duke records, please let me know!\nPlease let me know your preferred pronouns. You‚Äôll also be able to note this in the Getting to know you survey.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don‚Äôt hesitate to come and talk with me. I want to be a resource for you. If you prefer to speak with someone outside of the course, your advisers and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "slides/lec-1.html#accessibility",
    "href": "slides/lec-1.html#accessibility",
    "title": "Welcome to STA 210!",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nI am committed to making all course materials accessible and I‚Äôm always learning how to do this better. If any course component is not accessible to you in any way, please don‚Äôt hesitate to let me know."
  },
  {
    "objectID": "slides/lec-1.html#covid-policies",
    "href": "slides/lec-1.html#covid-policies",
    "title": "Welcome to STA 210!",
    "section": "COVID policies",
    "text": "COVID policies\n\nWear a mask at all times!\nRead and follow university guidance"
  },
  {
    "objectID": "slides/lec-1.html#late-work-waivers-regrades-policy",
    "href": "slides/lec-1.html#late-work-waivers-regrades-policy",
    "title": "Welcome to STA 210!",
    "section": "Late work, waivers, regrades policy",
    "text": "Late work, waivers, regrades policy\n\nWe have policies!\nRead about them on the course syllabus and refer back to them when you need it"
  },
  {
    "objectID": "slides/lec-1.html#collaboration-policy",
    "href": "slides/lec-1.html#collaboration-policy",
    "title": "Welcome to STA 210!",
    "section": "Collaboration policy",
    "text": "Collaboration policy\n\nOnly work that is clearly assigned as team work should be completed collaboratively.\nHomeworks must be completed individually. You may not directly share answers / code with others, however you are welcome to discuss the problems in general and ask for advice.\nExams must be completed individually. You may not discuss any aspect of the exam with peers. If you have questions, post as private questions on the course forum, only the teaching team will see and answer."
  },
  {
    "objectID": "slides/lec-1.html#sharing-reusing-code-policy",
    "href": "slides/lec-1.html#sharing-reusing-code-policy",
    "title": "Welcome to STA 210!",
    "section": "Sharing / reusing code policy",
    "text": "Sharing / reusing code policy\n\nWe are aware that a huge volume of code is available on the web, and many tasks may have solutions posted\nUnless explicitly stated otherwise, this course‚Äôs policy is that you may make use of any online resources (e.g.¬†RStudio Community, StackOverflow, etc.) but you must explicitly cite where you obtained any code you directly use or use as inspiration in your solution(s).\nAny recycled code that is discovered and is not explicitly cited will be treated as plagiarism, regardless of source"
  },
  {
    "objectID": "slides/lec-1.html#academic-integrity",
    "href": "slides/lec-1.html#academic-integrity",
    "title": "Welcome to STA 210!",
    "section": "Academic integrity",
    "text": "Academic integrity\n\nTo uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised."
  },
  {
    "objectID": "slides/lec-1.html#most-importantly",
    "href": "slides/lec-1.html#most-importantly",
    "title": "Welcome to STA 210!",
    "section": "Most importantly!",
    "text": "Most importantly!\nAsk if you‚Äôre not sure if something violates a policy!"
  },
  {
    "objectID": "slides/lec-1.html#five-tips-for-success",
    "href": "slides/lec-1.html#five-tips-for-success",
    "title": "Welcome to STA 210!",
    "section": "Five tips for success",
    "text": "Five tips for success\n\nComplete all the preparation work before class.\nAsk questions.\nDo the readings.\nDo the homework and lab.\nDon‚Äôt procrastinate and don‚Äôt let a week pass by with lingering questions."
  },
  {
    "objectID": "slides/lec-1.html#learning-during-a-pandemic",
    "href": "slides/lec-1.html#learning-during-a-pandemic",
    "title": "Welcome to STA 210!",
    "section": "Learning during a pandemic",
    "text": "Learning during a pandemic\nI want to make sure that you learn everything you were hoping to learn from this class. If this requires flexibility, please don‚Äôt hesitate to ask.\n\n\nYou never owe me personal information about your health (mental or physical) but you‚Äôre always welcome to talk to me. If I can‚Äôt help, I likely know someone who can.\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded during this crisis."
  },
  {
    "objectID": "slides/lec-1.html#this-weeks-tasks",
    "href": "slides/lec-1.html#this-weeks-tasks",
    "title": "Welcome to STA 210!",
    "section": "This week‚Äôs tasks",
    "text": "This week‚Äôs tasks\n\nGet a GitHub account if you don‚Äôt have one (some advice for choosing a username here)\nComplete the Getting to know you survey if you haven‚Äôt yet done so!\nRead the syllabus\nWatch out for next week‚Äôs announcement email, in your inbox sometime tomorrow"
  },
  {
    "objectID": "slides/lec-1.html#midori-says",
    "href": "slides/lec-1.html#midori-says",
    "title": "Welcome to STA 210!",
    "section": "Midori says‚Ä¶",
    "text": "Midori says‚Ä¶"
  }
]